{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wzspg5Ok5rb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpV4XOQzk6eN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJSeAJHbiQkZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9ufxTcqi1p_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJKFXHJni1tz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhbiuW2BU9Ec"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install torch torchvision torchmetrics thop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2od11trTFic"
      },
      "outputs": [],
      "source": [
        "! pip install torchprofile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP_mEN9aTPSC"
      },
      "outputs": [],
      "source": [
        "!pip install -U fvcore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdsXf207N8gV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import os\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "#from torchmetrics import JaccardIndex\n",
        "#from thop import profile, clever_format\n",
        "import time\n",
        "\n",
        "#from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
        "#import torchprofile\n",
        "\n",
        "#from models.deeplabv2.deeplabv2 import get_deeplab_v2\n",
        "\n",
        "\n",
        "from torchmetrics import JaccardIndex\n",
        "from thop import profile, clever_format\n",
        "import time\n",
        "\n",
        "from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
        "import torchprofile\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNWddRGrt1kp"
      },
      "source": [
        "**Cityscapes Dataset Download**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q0xtwU5EhPW"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4k4DE0eEjwr"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import pathlib\n",
        "drive.mount('/content/Drive')\n",
        "get_ipython().system('/content/Drive/MyDrive/Cityspaces/Cityspaces')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqu-NDJHFkGk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuEJmYHCeerC"
      },
      "source": [
        "**GTA5 Dataset download**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6C1U9y6hF4b"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjU52v_9P6Wj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pathlib\n",
        "drive.mount('/content/Drive')\n",
        "get_ipython().system('/content/Drive/MyDrive/GTA5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBX62-n6ZVgD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wJwQ6hxi4wh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_09FKOE7XLEG"
      },
      "source": [
        "**Model Clone**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPllYnf-NPeU"
      },
      "outputs": [],
      "source": [
        "# Clone the GitHub repository\n",
        "!git clone https://github.com/Gabrysse/MLDL2024_project1.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kkLfxwKNZ5J"
      },
      "outputs": [],
      "source": [
        "# Navigate to the project directory\n",
        "%cd MLDL2024_project1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vi5RIWMWOJba"
      },
      "outputs": [],
      "source": [
        "#from models.deeplabv2.deeplabv2 import get_deeplab_v2\n",
        "from models.bisenet.build_bisenet import BiSeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAC9VIa40hM9"
      },
      "outputs": [],
      "source": [
        "# Set device to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnnzlL6eVNsV"
      },
      "source": [
        "**Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "032jMg_kVQWJ"
      },
      "outputs": [],
      "source": [
        "# Define training parameters\n",
        "epochs = 50\n",
        "learning_rate = 0.01\n",
        "batch_size = 4\n",
        "train_resolution = (1280,720) #(1024, 512)\n",
        "test_resolution = (1024, 512)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3HtXvfzRp1R"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CityscapesDataset(Dataset):\n",
        "  def __init__(self, root_dir, im_transform ):\n",
        "\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    root_dir (string): Directory with all the images.\n",
        "    transform (callable, optional): Optional transform to be applied on a sample.\n",
        "    \"\"\"\n",
        "    self.root_dir = root_dir\n",
        "    self.im_transform = im_transform\n",
        "    #self.lab_transform = lab_transform\n",
        "    self.images = []\n",
        "    for subdir, dirs, files in os.walk(root_dir):\n",
        "      for file in files:\n",
        "        if file.endswith('_gtFine_color.png'):\n",
        "          self.images.append(os.path.join(subdir, file))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_name = self.images[idx]\n",
        "    image = Image.open(img_name).convert('RGB')\n",
        "    label_name = img_name.replace('_gtFine_color.png', '_gtFine_labelTrainIds.png')  #labelTrainIds\n",
        "    label = Image.open(label_name)\n",
        "\n",
        "\n",
        "    # Resize label using nearest-neighbor interpolation\n",
        "    label = TF.resize(label, (1024, 512), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "    label = np.array(label)  # Convert to numpy array\n",
        "    label = torch.from_numpy(label).long()  # Convert to LongTensor\n",
        "\n",
        "\n",
        "    if self.im_transform:\n",
        "\n",
        "      image = self.im_transform(image)\n",
        "\n",
        "    # if self.lab_transform:\n",
        "    #   label = self.lab_transform(label)\n",
        "\n",
        "    return image, label\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuDK4JddkZnR"
      },
      "outputs": [],
      "source": [
        "class GTA5Dataset(Dataset):\n",
        "  def __init__(self, root_dir, im_transform=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    root_dir (string): Directory with all the images and labels.\n",
        "    im_transform (callable, optional): Optional transform to be applied on a sample.\n",
        "    \"\"\"\n",
        "    self.root_dir = root_dir\n",
        "    self.im_transform = im_transform\n",
        "    self.images_dir = os.path.join(root_dir, 'images')\n",
        "    self.labels_dir = os.path.join(root_dir, 'labels')\n",
        "    self.images = [os.path.join(self.images_dir, file) for file in os.listdir(self.images_dir) if file.endswith('.png')]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_name = self.images[idx]\n",
        "    image = Image.open(img_name).convert('RGB')\n",
        "    label_name = img_name.replace('images', 'labels')  # Assuming label images are in the 'labels' folder with the same name\n",
        "    label = Image.open(label_name)\n",
        "\n",
        "    # Resize label using nearest-neighbor interpolation\n",
        "    label = TF.resize(label, (1280,720) , interpolation=transforms.InterpolationMode.NEAREST)\n",
        "    label = np.array(label)  # Convert to numpy array\n",
        "\n",
        "    # Define the maximum valid label ID\n",
        "    max_valid_id = 18\n",
        "    # Set all label IDs greater than max_valid_id to the 'ignore' class (e.g., 255)\n",
        "    label[label > max_valid_id] = 255\n",
        "\n",
        "\n",
        "    label = torch.from_numpy(label).long()  # Convert to LongTensor\n",
        "\n",
        "    if self.im_transform:\n",
        "      image = self.im_transform(image)\n",
        "\n",
        "    return image, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RxFO23631_3"
      },
      "source": [
        "**GTA5 Augmented Train Loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0RCkMU_lAhz"
      },
      "outputs": [],
      "source": [
        "# Create the dataset\n",
        "\n",
        "# im_transform=transforms.Compose([\n",
        "\n",
        "# transforms.ToTensor(),\n",
        "# transforms.Resize(train_resolution),\n",
        "\n",
        "# ])\n",
        "\n",
        "\n",
        "###-----   Augmentation Transforms:\n",
        "\n",
        "# Create the dataset with augmentations\n",
        "im_transform = transforms.Compose([\n",
        "transforms.ToTensor(),\n",
        "transforms.Resize(train_resolution),\n",
        "#transforms.RandomHorizontalFlip(p=0.5),  # Apply horizontal flip with 50% probability\n",
        "#transforms.RandomApply([transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5))], p=0.5)#,  # Apply Gaussian Blur with 50% probability\n",
        "transforms.RandomApply([transforms.ColorJitter(brightness=0.5)], p=0.5),  # Apply brightness adjustment with 50% probability\n",
        "# Add more augmentations here if needed\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "gta5_dataset = GTA5Dataset(root_dir='/content/Drive/MyDrive/GTA5', im_transform=im_transform)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xskaQe0nV0K"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(gta5_dataset, batch_size=batch_size, shuffle=True, num_workers=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UszT9qhVJl44"
      },
      "source": [
        "**Citescapes Train Loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjWP2n62UBn3"
      },
      "outputs": [],
      "source": [
        "# # Define a transform if you need to preprocess the images\n",
        "# transformed_dataset = CityscapesDataset(root_dir='/content/Cityscapes/Cityspaces/gtFine/train', #/content/Cityscapes/Cityspaces/gtFine/train\n",
        "# im_transform=transforms.Compose([\n",
        "\n",
        "# transforms.ToTensor(),\n",
        "# transforms.Resize(train_resolution),\n",
        "\n",
        "# ]), )\n",
        "\n",
        "\n",
        "# train_loader = DataLoader(transformed_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0Yr3sirzs00"
      },
      "outputs": [],
      "source": [
        "# Load the DeepLabV2 model\n",
        "#model = get_deeplab_v2(num_classes=19, pretrain=False)\n",
        "\n",
        "# Load the BiSeNet model\n",
        "model = BiSeNet(num_classes=19,context_path='resnet18') #'resnet18')  #'resnet101')  #BiSeNet\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "# Define the CrossEntropyLoss with ignore_index set to 255\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fNiWtGSzs8P"
      },
      "outputs": [],
      "source": [
        "# Define the metric for mIoU\n",
        "miou_metric = JaccardIndex(num_classes=19, task='multiclass' , ignore_index=255).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8p-LLxDzMNb"
      },
      "outputs": [],
      "source": [
        "# Function to compute latency\n",
        "def measure_latency(model, input_tensor, repetitions=100):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        start = time.time()\n",
        "        for _ in range(repetitions):\n",
        "            _ = model(input_tensor)\n",
        "        end = time.time()\n",
        "    latency = (end - start) / repetitions\n",
        "    return latency\n",
        "\n",
        "\n",
        "\n",
        "# Measure FLOPs and number of parameters\n",
        "\n",
        "\n",
        "dummy_input = torch.randn(1, 3, 1024, 512).to(device)\n",
        "\n",
        "height = 1024\n",
        "width = 512\n",
        "image =torch.zeros((1,3, height, width)).to(device)   # torch.randn(1,3, 1024, 512).to(device)#\n",
        "\n",
        "model.eval()\n",
        "flops = FlopCountAnalysis(model, image)\n",
        "print(flop_count_table(flops))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljOeeMI_Qlp6"
      },
      "outputs": [],
      "source": [
        "# Measure FLOPs and parameters using torchprofile\n",
        "dummy_input = torch.randn(1, 3, 1024,512).to(device)\n",
        "model.eval()\n",
        "flops = torchprofile.profile_macs(model, args=(dummy_input,))\n",
        "\n",
        "params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "print(f' flops={flops}\\n params={params} ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFgrmuBxbZL_"
      },
      "source": [
        "**IoU Calculation Function for Classes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpeSv9KSbXv6"
      },
      "outputs": [],
      "source": [
        "def fast_hist(a, b, n):\n",
        "    '''\n",
        "    a and b are label and prediction respectively\n",
        "    n is the number of classes\n",
        "    '''\n",
        "    #k = (a >= 0) & (a < n)\n",
        "    k = (b >= 0) & (b < n)\n",
        "    return np.bincount(n * a[k].astype(int) + b[k], minlength=n ** 2).reshape(n, n)\n",
        "\n",
        "\n",
        "def per_class_iou(hist):\n",
        "    epsilon = 1e-5\n",
        "    return (np.diag(hist)) / (hist.sum(1) + hist.sum(0) - np.diag(hist) + epsilon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Iwy_KA5TNwE"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/Drive')\n",
        "get_ipython().system('/content/Drive/MyDrive/Checkpoints/3b/3b_bright_0.01_4')"
      ],
      "metadata": {
        "id": "8kxTz4ev204g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d52ce0c7-0c21-44a8-b5c4-b0bcbcc6d334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/Drive; to attempt to forcibly remount, call drive.mount(\"/content/Drive\", force_remount=True).\n",
            "/bin/bash: line 1: /content/Drive/MyDrive/Checkpoints/3b/3b_bright_0.01_4: Is a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to save the model\n",
        "def save_checkpoint(epoch, model, optimizer, save_dir='/content/Drive/MyDrive/Checkpoints/3b/3b_bright_0.01_4'):\n",
        "    # Ensure the save directory exists\n",
        "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Define the model filename with the epoch number\n",
        "    checkpoint_filename = f'checkpoint_epoch_{epoch}.pth'\n",
        "    checkpoint_path = os.path.join(save_dir, checkpoint_filename)\n",
        "\n",
        "    # Save the model and optimizer state dictionaries\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, checkpoint_path)\n",
        "    print(f'Model and optimizer saved to {checkpoint_path}')\n",
        "\n",
        "# Function to load the model\n",
        "def load_checkpoint(epoch, model, optimizer, save_dir='/content/Drive/MyDrive/Checkpoints/3b/3b_bright_0.01_4'):\n",
        "    checkpoint_filename = f'checkpoint_epoch_{epoch}.pth'\n",
        "    checkpoint_path = os.path.join(save_dir, checkpoint_filename)\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.isfile(checkpoint_path):\n",
        "        raise FileNotFoundError(f\"The specified file was not found: {checkpoint_path}\")\n",
        "\n",
        "    # Load the model and optimizer state dictionaries\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "\n",
        "    print(f'Model and optimizer loaded from {checkpoint_path}, resuming at epoch {start_epoch}')\n",
        "    return model, optimizer, start_epoch\n",
        "\n"
      ],
      "metadata": {
        "id": "0ZKhvu742y5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CL_bZe4S2ynQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1T9gxM10O1P"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "# Resume training from the last checkpoint if available\n",
        "resume_training =False   # Set this to True if you want to resume training\n",
        "\n",
        "epochs = 50  # Set this to the total number of epochs you want to train\n",
        "\n",
        "if resume_training:\n",
        "    epoch_to_resume =0 #9,19,29,39,49  # Set this to the epoch from which you want to resume\n",
        "    try:\n",
        "        model, optimizer, start_epoch = load_checkpoint(epoch_to_resume, model, optimizer)\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(e)\n",
        "        start_epoch = 0\n",
        "else:\n",
        "    start_epoch = 0\n",
        "\n",
        "for epoch in range(start_epoch,epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    miou_metric.reset()\n",
        "    counter=1\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        #labels = labels.squeeze(1)\n",
        "\n",
        "        loss = criterion(outputs[0], labels.long())\n",
        "        #print(loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #print(counter)\n",
        "        counter+=1\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        miou_metric.update(outputs[0].argmax(dim=1), labels)\n",
        "\n",
        "     # Save the model every 10 epochs\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        save_checkpoint(epoch, model, optimizer)\n",
        "\n",
        "    miou = miou_metric.compute().item()\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader)}, Train mIoU: {miou}')\n",
        "\n",
        "# Measure latency after training\n",
        "latency = measure_latency(model, dummy_input)\n",
        "print(f\"FLOPs: {flops}, Params: {params}, Latency: {latency:.6f} seconds\")\n",
        "\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTh46WFVkFLq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpQ67CRAKM-t"
      },
      "source": [
        "**Test Loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8F7HxrMSK3X"
      },
      "outputs": [],
      "source": [
        "# Define a transform if you need to preprocess the images\n",
        "transformed_dataset = CityscapesDataset(root_dir='/content/Drive/MyDrive/Cityspaces/Cityspaces/gtFine/val', #/content/Cityscapes/Cityspaces/gtFine/train\n",
        "im_transform=transforms.Compose([\n",
        "\n",
        "transforms.ToTensor(),\n",
        "transforms.Resize(test_resolution),\n",
        "\n",
        "]), )\n",
        "\n",
        "\n",
        "test_loader = DataLoader(transformed_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ3uZ37_S_5C"
      },
      "source": [
        "**Inference and mIoU calculation on test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZd3_wXY4DbS"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "model.eval()\n",
        "miou_metric.reset()\n",
        "\n",
        "all_classes_iou=np.zeros(19)\n",
        "test_counter=0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Resize predictions to the original Cityscapes resolution\n",
        "        outputs = TF.resize(outputs, test_resolution, interpolation=Image.NEAREST)\n",
        "        print(outputs.shape , labels.shape)\n",
        "\n",
        "\n",
        "        #calcualting IoU for each class and for each (image,label) pair separately\n",
        "        current_batch_size = labels.size(0)\n",
        "        for i in range(current_batch_size):\n",
        "\n",
        "            mask=labels[i,:,:].cpu().numpy().flatten() != 255\n",
        "            #hist=fast_hist(outputs[i,:,:,:].argmax(dim=0).cpu().numpy().flatten()[mask] , labels[i,:,:].cpu().numpy().flatten()[mask], 19)\n",
        "\n",
        "            hist=fast_hist(outputs[i,:,:,:].argmax(dim=0).cpu().numpy().flatten() , labels[i,:,:].cpu().numpy().flatten(), 19)\n",
        "\n",
        "            all_classes_iou=all_classes_iou+per_class_iou(hist)\n",
        "            test_counter = test_counter +1\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwqEwifUcjgf"
      },
      "outputs": [],
      "source": [
        "test_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3roYr0uWqMQ"
      },
      "outputs": [],
      "source": [
        "all_classes_mIOU=(all_classes_iou/test_counter).round(3)  #calculating mean intersection over union for each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cZkG6AMWy5f"
      },
      "outputs": [],
      "source": [
        "all_classes_mIOU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhoYFSI4XY3p"
      },
      "outputs": [],
      "source": [
        "mIoU=all_classes_mIOU.mean()  #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKud9H4MXcjx"
      },
      "outputs": [],
      "source": [
        "mIoU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQDH0xjZdCoZ"
      },
      "source": [
        "**GTA5 Labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MktUOoKOdGMq"
      },
      "outputs": [],
      "source": [
        "from abc import ABCMeta\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "class BaseGTALabels(metaclass=ABCMeta):\n",
        "    pass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class GTA5Label:\n",
        "    ID: int\n",
        "    color: Tuple[int, int, int]\n",
        "\n",
        "\n",
        "class GTA5Labels_TaskCV2017(BaseGTALabels):\n",
        "    road = GTA5Label(ID=0, color=(128, 64, 128))\n",
        "    sidewalk = GTA5Label(ID=1, color=(244, 35, 232))\n",
        "    building = GTA5Label(ID=2, color=(70, 70, 70))\n",
        "    wall = GTA5Label(ID=3, color=(102, 102, 156))\n",
        "    fence = GTA5Label(ID=4, color=(190, 153, 153))\n",
        "    pole = GTA5Label(ID=5, color=(153, 153, 153))\n",
        "    light = GTA5Label(ID=6, color=(250, 170, 30))\n",
        "    sign = GTA5Label(ID=7, color=(220, 220, 0))\n",
        "    vegetation = GTA5Label(ID=8, color=(107, 142, 35))\n",
        "    terrain = GTA5Label(ID=9, color=(152, 251, 152))\n",
        "    sky = GTA5Label(ID=10, color=(70, 130, 180))\n",
        "    person = GTA5Label(ID=11, color=(220, 20, 60))\n",
        "    rider = GTA5Label(ID=12, color=(255, 0, 0))\n",
        "    car = GTA5Label(ID=13, color=(0, 0, 142))\n",
        "    truck = GTA5Label(ID=14, color=(0, 0, 70))\n",
        "    bus = GTA5Label(ID=15, color=(0, 60, 100))\n",
        "    train = GTA5Label(ID=16, color=(0, 80, 100))\n",
        "    motocycle = GTA5Label(ID=17, color=(0, 0, 230))\n",
        "    bicycle = GTA5Label(ID=18, color=(119, 11, 32))\n",
        "\n",
        "    list_ = [\n",
        "        road,\n",
        "        sidewalk,\n",
        "        building,\n",
        "        wall,\n",
        "        fence,\n",
        "        pole,\n",
        "        light,\n",
        "        sign,\n",
        "        vegetation,\n",
        "        terrain,\n",
        "        sky,\n",
        "        person,\n",
        "        rider,\n",
        "        car,\n",
        "        truck,\n",
        "        bus,\n",
        "        train,\n",
        "        motocycle,\n",
        "        bicycle,\n",
        "    ]\n",
        "\n",
        "    @property\n",
        "    def support_id_list(self):\n",
        "        ret = [label.ID for label in self.list_]\n",
        "        return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0BRk3RlZNiY"
      },
      "outputs": [],
      "source": [
        "class_labels = []\n",
        "for label_name, label in GTA5Labels_TaskCV2017.__dict__.items():\n",
        "  if isinstance(label, GTA5Label):\n",
        "    class_labels.append(label_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcvRxtpLZU1s"
      },
      "outputs": [],
      "source": [
        "class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLgml_o1al2p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR6dfnTWZNq6"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame\n",
        "all_classes_mIOU_DF = pd.DataFrame({\n",
        "'class_Label': class_labels,\n",
        "'class_IoU': all_classes_iou\n",
        "})\n",
        "\n",
        "all_classes_mIOU_DF\n"
      ]
    },
    {
      "source": [
        "# @title class_IoU\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "all_classes_mIOU_DF['class_IoU'].plot(kind='hist', bins=20, title='class_IoU')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "cellView": "form",
        "id": "280Lf-oktoep",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "71f3fe6d-8cec-41ae-8484-889822bc3f9c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3BFrswajh3L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agdDp61Fi41m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCwYG2xri45j"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}