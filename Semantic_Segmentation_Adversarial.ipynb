{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "QfHducy3duRw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p7Px2pA7SDFj"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import os\n",
        "\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "#from torchmetrics import JaccardIndex\n",
        "#from thop import profile, clever_format\n",
        "import time\n",
        "\n",
        "#from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
        "#import torchprofile\n",
        "\n",
        "#from models.deeplabv2.deeplabv2 import get_deeplab_v2\n",
        "\n",
        "\n",
        "#from torchmetrics import JaccardIndex\n",
        "#from thop import profile, clever_format\n",
        "\n",
        "\n",
        "#from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
        "#import torchprofile\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rf_tIixzSo2z"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TO60nDAdTbIy"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cityscapes Dataset Download**"
      ],
      "metadata": {
        "id": "zNWddRGrt1kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install gdown\n",
        "\n"
      ],
      "metadata": {
        "id": "5q0xtwU5EhPW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import gdown\n",
        "\n",
        "#url = 'https://drive.google.com/uc?id=1Qb4UrNsjvlU-wEsR9d7rckB0YS_LXgb2'\n",
        "#output = 'your_dataset.zip'  # Change this to the desired output filename\n",
        "#gdown.download(url, output, quiet=False)\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/Drive')\n",
        "get_ipython().system('/content/Drive/MyDrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4k4DE0eEjwr",
        "outputId": "7cce6754-6db8-435b-c2cd-8f2d98685465"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/Drive; to attempt to forcibly remount, call drive.mount(\"/content/Drive\", force_remount=True).\n",
            "/bin/bash: line 1: /content/Drive/MyDrive: Is a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get_ipython().system('unzip /content/your_dataset.zip -d /content/')"
      ],
      "metadata": {
        "id": "wqu-NDJHFkGk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GTA5 Dataset download**"
      ],
      "metadata": {
        "id": "XuEJmYHCeerC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset link :"
      ],
      "metadata": {
        "id": "N6C1U9y6hF4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url=' https://drive.google.com/uc?id=1xYxlcMR2WFCpayNrW2-Rb7N-950vvl23'\n",
        "#output = 'GTA5.zip'  # Change this to the desired output filename\n",
        "#gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "id": "wjU52v_9P6Wj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get_ipython().system('unzip /content/GTA5.zip -d /content/')"
      ],
      "metadata": {
        "id": "RBX62-n6ZVgD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Clone**"
      ],
      "metadata": {
        "id": "_09FKOE7XLEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the GitHub repository\n",
        "!git clone https://github.com/Gabrysse/MLDL2024_project1.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPllYnf-NPeU",
        "outputId": "9db307dd-ba39-4b7e-cf5e-6b1b00a07b1c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MLDL2024_project1' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Navigate to the project directory\n",
        "%cd MLDL2024_project1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kkLfxwKNZ5J",
        "outputId": "25d3b27b-60e4-4fbf-bffb-bbea2784abc6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MLDL2024_project1/MLDL2024_project1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from models.deeplabv2.deeplabv2 import get_deeplab_v2\n",
        "from models.bisenet.build_bisenet import BiSeNet"
      ],
      "metadata": {
        "id": "Vi5RIWMWOJba"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "OHxU7YydbOqr"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "PAC9VIa40hM9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vqy92p1ITbNK"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parameters**"
      ],
      "metadata": {
        "id": "mnnzlL6eVNsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training parameters\n",
        "epochs = 50\n",
        "learning_rate = 0.01\n",
        "batch_size = 4\n",
        "train_resolution = (1280,720) #(1024, 512)\n",
        "test_resolution = (1024, 512)\n"
      ],
      "metadata": {
        "id": "032jMg_kVQWJ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CityscapesDataset(Dataset):\n",
        "  def __init__(self, root_dir, im_transform ):\n",
        "\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    root_dir (string): Directory with all the images.\n",
        "    transform (callable, optional): Optional transform to be applied on a sample.\n",
        "    \"\"\"\n",
        "    self.root_dir = root_dir\n",
        "    self.im_transform = im_transform\n",
        "    #self.lab_transform = lab_transform\n",
        "    self.images = []\n",
        "    for subdir, dirs, files in os.walk(root_dir):\n",
        "      for file in files:\n",
        "        if file.endswith('_gtFine_color.png'):\n",
        "          self.images.append(os.path.join(subdir, file))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_name = self.images[idx]\n",
        "    image = Image.open(img_name).convert('RGB')\n",
        "    label_name = img_name.replace('_gtFine_color.png', '_gtFine_labelTrainIds.png')  #labelTrainIds\n",
        "    label = Image.open(label_name)\n",
        "\n",
        "\n",
        "    # Resize label using nearest-neighbor interpolation\n",
        "    label = TF.resize(label, (1024, 512), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "    label = np.array(label)  # Convert to numpy array\n",
        "    label = torch.from_numpy(label).long()  # Convert to LongTensor\n",
        "\n",
        "\n",
        "    if self.im_transform:\n",
        "\n",
        "      image = self.im_transform(image)\n",
        "\n",
        "    # if self.lab_transform:\n",
        "    #   label = self.lab_transform(label)\n",
        "\n",
        "    return image, label\n",
        "\n"
      ],
      "metadata": {
        "id": "Z3HtXvfzRp1R"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GTA5Dataset(Dataset):\n",
        "  def __init__(self, root_dir, im_transform=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    root_dir (string): Directory with all the images and labels.\n",
        "    im_transform (callable, optional): Optional transform to be applied on a sample.\n",
        "    \"\"\"\n",
        "    self.root_dir = root_dir\n",
        "    self.im_transform = im_transform\n",
        "    self.images_dir = os.path.join(root_dir, 'images')\n",
        "    self.labels_dir = os.path.join(root_dir, 'labels')\n",
        "    self.images = [os.path.join(self.images_dir, file) for file in os.listdir(self.images_dir) if file.endswith('.png')]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_name = self.images[idx]\n",
        "    image = Image.open(img_name).convert('RGB')\n",
        "    label_name = img_name.replace('images', 'labels')  # Assuming label images are in the 'labels' folder with the same name\n",
        "    label = Image.open(label_name)\n",
        "\n",
        "    # Resize label using nearest-neighbor interpolation\n",
        "    label = TF.resize(label, (1280,720) , interpolation=transforms.InterpolationMode.NEAREST)\n",
        "    label = np.array(label)  # Convert to numpy array\n",
        "\n",
        "    # Define the maximum valid label ID\n",
        "    max_valid_id = 18\n",
        "    # Set all label IDs greater than max_valid_id to the 'ignore' class (e.g., 255)\n",
        "    label[label > max_valid_id] = 255\n",
        "\n",
        "\n",
        "    label = torch.from_numpy(label).long()  # Convert to LongTensor\n",
        "\n",
        "    if self.im_transform:\n",
        "      image = self.im_transform(image)\n",
        "\n",
        "    return image, label\n"
      ],
      "metadata": {
        "id": "nuDK4JddkZnR"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GTA5 Augmented Train Loader**"
      ],
      "metadata": {
        "id": "5RxFO23631_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the dataset\n",
        "\n",
        "# im_transform=transforms.Compose([\n",
        "\n",
        "# transforms.ToTensor(),\n",
        "# transforms.Resize(train_resolution),\n",
        "\n",
        "# ])\n",
        "\n",
        "\n",
        "###-----   Augmentation Transforms:\n",
        "\n",
        "# Create the dataset with augmentations\n",
        "im_transform = transforms.Compose([\n",
        "transforms.ToTensor(),\n",
        "transforms.Resize(train_resolution),\n",
        "\n",
        "#transforms.RandomHorizontalFlip(p=0.5),  # Apply horizontal flip with 50% probability\n",
        "transforms.RandomApply([transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5))], p=0.5)  # Apply Gaussian Blur with 50% probability\n",
        "#transforms.RandomApply([transforms.ColorJitter(brightness=0.5)], p=0.5),  # Apply brightness adjustment with 50% probability\n",
        "\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "gta5_dataset = GTA5Dataset(root_dir='/content/Drive/MyDrive/GTA5', im_transform=im_transform)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R0RCkMU_lAhz"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gta5_loader = DataLoader(gta5_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
      ],
      "metadata": {
        "id": "-xskaQe0nV0K"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(gta5_loader.dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efLvFSi9TpSS",
        "outputId": "cfa36769-0746-4c75-9ee0-e395df27844f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kdr5y9MYpY68"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cityscapes Train Data Loader**"
      ],
      "metadata": {
        "id": "INdOxe22pZwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a transform if you need to preprocess the images\n",
        "transformed_dataset = CityscapesDataset(root_dir='/content/Drive/MyDrive/Cityspaces/Cityspaces/gtFine/train', #/content/Cityscapes/Cityspaces/gtFine/train\n",
        "im_transform=transforms.Compose([\n",
        "\n",
        "transforms.ToTensor(),\n",
        "transforms.Resize(train_resolution),\n",
        "\n",
        "]), )\n",
        "\n",
        "\n",
        "cityscape_train_loader = DataLoader(transformed_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NAR7mNBDpZwZ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cityscape_train_loader.dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZY5BRvMpY_q",
        "outputId": "a69182c2-cec7-4aa8-d36d-8240cc0d5c6d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1572"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "goV3X29QpZCa"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cityscapes Validation Data Loader**"
      ],
      "metadata": {
        "id": "OpQ67CRAKM-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a transform if you need to preprocess the images\n",
        "transformed_dataset = CityscapesDataset(root_dir='/content/Drive/MyDrive/Cityspaces/Cityspaces/gtFine/val', #/content/Cityscapes/Cityspaces/gtFine/train\n",
        "im_transform=transforms.Compose([\n",
        "\n",
        "transforms.ToTensor(),\n",
        "transforms.Resize(test_resolution),\n",
        "\n",
        "]), )\n",
        "\n",
        "\n",
        "cityscape_val_loader = DataLoader(transformed_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q8F7HxrMSK3X"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cityscape_val_loader.dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTLxiqUTWgY5",
        "outputId": "50153935-c7c5-4cb0-e2c7-97ef4dd1a9c0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kLmipLJvWgdE"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_7OV5zaXT8d9"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the DeepLabV2 model\n",
        "#model = get_deeplab_v2(num_classes=19, pretrain=False)\n",
        "\n",
        "# Load the BiSeNet model\n",
        "model = BiSeNet(num_classes=19,context_path='resnet18') #'resnet18')  #'resnet101')  #BiSeNet\n",
        "\n",
        "\n",
        "model = model.to('cuda')\n",
        "\n",
        "\n",
        "\n",
        "# Define the CrossEntropyLoss with ignore_index set to 255\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "F0Yr3sirzs00"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IoU Calculation Function for Classes**"
      ],
      "metadata": {
        "id": "dFgrmuBxbZL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fast_hist(a, b, n):\n",
        "    '''\n",
        "    a and b are label and prediction respectively\n",
        "    n is the number of classes\n",
        "    '''\n",
        "    #k = (a >= 0) & (a < n)\n",
        "    k = (b >= 0) & (b < n)\n",
        "    return np.bincount(n * a[k].astype(int) + b[k], minlength=n ** 2).reshape(n, n)\n",
        "\n",
        "\n",
        "def per_class_iou(hist):\n",
        "    epsilon = 1e-5\n",
        "    return (np.diag(hist)) / (hist.sum(1) + hist.sum(0) - np.diag(hist) + epsilon)"
      ],
      "metadata": {
        "id": "lpeSv9KSbXv6"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yHdqsqOKU994"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discriminator Model**"
      ],
      "metadata": {
        "id": "8sFGNvRuU_BI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FCDiscriminator(nn.Module):\n",
        "  def __init__(self, num_classes, ndf=64):\n",
        "    super(FCDiscriminator, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(num_classes, ndf, kernel_size=4, stride=2, padding=1)\n",
        "    self.conv2 = nn.Conv2d(ndf, ndf*2, kernel_size=4, stride=2, padding=1)\n",
        "    self.conv3 = nn.Conv2d(ndf*2, ndf*4, kernel_size=4, stride=2, padding=1)\n",
        "    self.conv4 = nn.Conv2d(ndf*4, ndf*8, kernel_size=4, stride=2, padding=1)\n",
        "    self.classifier = nn.Conv2d(ndf*8, 1, kernel_size=4, stride=2, padding=1)\n",
        "    self.leaky_relu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.leaky_relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.leaky_relu(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.leaky_relu(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.leaky_relu(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "stauaKHyVNhl"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CLpscmtdVNlO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BiSeNet Model Loading**"
      ],
      "metadata": {
        "id": "GifSRO_W0ZZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the BiSeNet model\n",
        "model = BiSeNet(num_classes=19,context_path='resnet18') #'resnet18')  #'resnet101')  #BiSeNet\n",
        "\n",
        "\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "AXSjBgXEVNpe"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qqqqrbPYVNru"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VEy08oNukSUY"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adversarial Training**"
      ],
      "metadata": {
        "id": "RNLU2rlKrD6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "\n",
        "# Assuming 'model' is your segmentation model and 'FCDiscriminator' is defined as above\n",
        "# Initialize models\n",
        "model = model.to('cuda')\n",
        "discriminator = FCDiscriminator(num_classes=19).to('cuda')  # Number of classes for segmentation task\n",
        "\n",
        "# Optimizers\n",
        "optimizer_model = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer_discriminator = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
        "\n",
        "# Loss functions\n",
        "criterion_segmentation = nn.CrossEntropyLoss(ignore_index=255)  # Loss function for segmentation model\n",
        "criterion_discriminator = nn.BCEWithLogitsLoss()                # Loss function for discriminator model\n",
        "\n",
        "# Create an infinite iterator for the smaller dataset\n",
        "target_iter = itertools.cycle(cityscape_train_loader)   # target is smaller\n",
        "\n",
        "# Main training loop\n",
        "for epoch in range(epochs):\n",
        "    # Reset the target iterator every epoch, because it is a larger dataset\n",
        "    source_iter = iter(gta5_loader)\n",
        "\n",
        "    # If source image loader is the larger dataset\n",
        "    for _ in range(len(gta5_loader)):\n",
        "        # Get a batch from the source dataset\n",
        "        source_data = next(source_iter)\n",
        "        source_images, source_labels = source_data\n",
        "        source_images = source_images.to('cuda')\n",
        "        source_labels = source_labels.to('cuda')\n",
        "\n",
        "        # Get a batch from the target dataset\n",
        "        target_data = next(target_iter)\n",
        "        target_images, _ = target_data\n",
        "        target_images = target_images.to('cuda')\n",
        "\n",
        "        ############### Train segmentation model with source and target ##################\n",
        "\n",
        "        ########## Train segmentation model with source images ##########\n",
        "        model.train()\n",
        "        optimizer_model.zero_grad()\n",
        "        source_pred = model(source_images)\n",
        "        loss_segmentation = criterion_segmentation(source_pred[0], source_labels)\n",
        "        loss_segmentation.backward()\n",
        "\n",
        "        ########## Train segmentation model with target images ##########\n",
        "        target_pred = model(target_images)\n",
        "        target_pred_softmax = F.softmax(target_pred[0], dim=1)  # Apply softmax to the model output\n",
        "\n",
        "        # Don't accumulate grads in Discriminator\n",
        "        for param in discriminator.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        pred_target = discriminator(target_pred_softmax)  # Use softmax output as input for discriminator\n",
        "\n",
        "        # Very important: Label as 1 for target to fool discriminator\n",
        "        target_label = torch.ones_like(pred_target).to('cuda')\n",
        "\n",
        "        loss_adv = criterion_discriminator(pred_target, target_label)\n",
        "\n",
        "        # Backpropagate the adversarial loss through the segmentation model only\n",
        "        loss_adv.backward()  # Backpropagate loss to update only segmentation model's parameters\n",
        "\n",
        "        ############# Train discriminator with source and target ###########################\n",
        "\n",
        "        ########## Train discriminator with source ##########\n",
        "        source_pred = model(source_images)\n",
        "        source_pred = source_pred[0].detach()  # Detach source_pred from the graph to prevent gradients from flowing into 'model'\n",
        "\n",
        "        # Enable gradient computation for discriminator parameters\n",
        "        for param in discriminator.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        discriminator_out = discriminator(F.softmax(source_pred, dim=1))\n",
        "\n",
        "        # Calculate loss for discriminator\n",
        "        source_label = torch.ones_like(discriminator_out).to('cuda')  # Label as 1 for source\n",
        "        loss_adv = criterion_discriminator(discriminator_out, source_label)\n",
        "\n",
        "        optimizer_discriminator.zero_grad()\n",
        "        loss_adv.backward()\n",
        "\n",
        "        ########## Train discriminator with target ##########\n",
        "        target_pred = model(target_images)\n",
        "        target_pred = target_pred[0].detach()  # Detach target_pred from the graph to prevent gradients from flowing into 'model'\n",
        "\n",
        "        discriminator_out = discriminator(F.softmax(target_pred, dim=1))\n",
        "\n",
        "        # Calculate loss for discriminator\n",
        "        target_label = torch.zeros_like(discriminator_out).to('cuda')  # Label as 0 for target\n",
        "        loss_adv = criterion_discriminator(discriminator_out, target_label)\n",
        "        loss_adv.backward()\n",
        "\n",
        "        # Update the models\n",
        "        optimizer_model.step()\n",
        "        optimizer_discriminator.step()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YzpD_4MgU-CL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VmQSb2xtVCbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference and mIoU calculation on test set**"
      ],
      "metadata": {
        "id": "AZ3uZ37_S_5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "\n",
        "all_classes_iou=np.zeros(19)\n",
        "test_counter=0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in cityscape_val_loader:          #test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Resize predictions to the original Cityscapes resolution\n",
        "        outputs = TF.resize(outputs, test_resolution, interpolation=Image.NEAREST)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #calcualting IoU for each class and for each (image,label) pair separately\n",
        "\n",
        "        for i in range (batch_size):\n",
        "\n",
        "          #mask=labels[i,:,:].cpu().numpy().flatten() != 255\n",
        "          #hist=fast_hist(outputs[i,:,:,:].argmax(dim=0).cpu().numpy().flatten()[mask] , labels[i,:,:].cpu().numpy().flatten()[mask], 19)\n",
        "\n",
        "          hist=fast_hist(outputs[i,:,:,:].argmax(dim=0).cpu().numpy().flatten() , labels[i,:,:].cpu().numpy().flatten(), 19)\n",
        "\n",
        "          all_classes_iou=all_classes_iou+per_class_iou(hist)\n",
        "          test_counter = test_counter +1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KZd3_wXY4DbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_counter"
      ],
      "metadata": {
        "id": "bwqEwifUcjgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_classes_mIOU=(all_classes_iou/test_counter).round(3)  #calculating mean intersection over union for each class"
      ],
      "metadata": {
        "id": "e3roYr0uWqMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_classes_mIOU"
      ],
      "metadata": {
        "id": "3cZkG6AMWy5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mIoU=all_classes_mIOU.mean()  #"
      ],
      "metadata": {
        "id": "IhoYFSI4XY3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mIoU"
      ],
      "metadata": {
        "id": "BKud9H4MXcjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GTA5 Labels**"
      ],
      "metadata": {
        "id": "QQDH0xjZdCoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABCMeta\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "class BaseGTALabels(metaclass=ABCMeta):\n",
        "    pass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class GTA5Label:\n",
        "    ID: int\n",
        "    color: Tuple[int, int, int]\n",
        "\n",
        "\n",
        "class GTA5Labels_TaskCV2017(BaseGTALabels):\n",
        "    road = GTA5Label(ID=0, color=(128, 64, 128))\n",
        "    sidewalk = GTA5Label(ID=1, color=(244, 35, 232))\n",
        "    building = GTA5Label(ID=2, color=(70, 70, 70))\n",
        "    wall = GTA5Label(ID=3, color=(102, 102, 156))\n",
        "    fence = GTA5Label(ID=4, color=(190, 153, 153))\n",
        "    pole = GTA5Label(ID=5, color=(153, 153, 153))\n",
        "    light = GTA5Label(ID=6, color=(250, 170, 30))\n",
        "    sign = GTA5Label(ID=7, color=(220, 220, 0))\n",
        "    vegetation = GTA5Label(ID=8, color=(107, 142, 35))\n",
        "    terrain = GTA5Label(ID=9, color=(152, 251, 152))\n",
        "    sky = GTA5Label(ID=10, color=(70, 130, 180))\n",
        "    person = GTA5Label(ID=11, color=(220, 20, 60))\n",
        "    rider = GTA5Label(ID=12, color=(255, 0, 0))\n",
        "    car = GTA5Label(ID=13, color=(0, 0, 142))\n",
        "    truck = GTA5Label(ID=14, color=(0, 0, 70))\n",
        "    bus = GTA5Label(ID=15, color=(0, 60, 100))\n",
        "    train = GTA5Label(ID=16, color=(0, 80, 100))\n",
        "    motocycle = GTA5Label(ID=17, color=(0, 0, 230))\n",
        "    bicycle = GTA5Label(ID=18, color=(119, 11, 32))\n",
        "\n",
        "    list_ = [\n",
        "        road,\n",
        "        sidewalk,\n",
        "        building,\n",
        "        wall,\n",
        "        fence,\n",
        "        pole,\n",
        "        light,\n",
        "        sign,\n",
        "        vegetation,\n",
        "        terrain,\n",
        "        sky,\n",
        "        person,\n",
        "        rider,\n",
        "        car,\n",
        "        truck,\n",
        "        bus,\n",
        "        train,\n",
        "        motocycle,\n",
        "        bicycle,\n",
        "    ]\n",
        "\n",
        "    @property\n",
        "    def support_id_list(self):\n",
        "        ret = [label.ID for label in self.list_]\n",
        "        return ret"
      ],
      "metadata": {
        "id": "MktUOoKOdGMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = []\n",
        "for label_name, label in GTA5Labels_TaskCV2017.__dict__.items():\n",
        "  if isinstance(label, GTA5Label):\n",
        "    class_labels.append(label_name)"
      ],
      "metadata": {
        "id": "M0BRk3RlZNiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels"
      ],
      "metadata": {
        "id": "bcvRxtpLZU1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "NLgml_o1al2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame\n",
        "all_classes_mIOU_DF = pd.DataFrame({\n",
        "'class_Label': class_labels,\n",
        "'class_IoU': all_classes_iou\n",
        "})\n",
        "\n",
        "all_classes_mIOU_DF\n"
      ],
      "metadata": {
        "id": "HR6dfnTWZNq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nu1PFhLBqxOV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}