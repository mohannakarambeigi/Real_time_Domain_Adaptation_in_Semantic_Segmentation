{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install necessary libraries"
      ],
      "metadata": {
        "id": "7cGpOIJcUhzw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhbiuW2BU9Ec"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install torch torchvision torchmetrics thop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2od11trTFic"
      },
      "outputs": [],
      "source": [
        "! pip install torchprofile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP_mEN9aTPSC"
      },
      "outputs": [],
      "source": [
        "!pip install -U fvcore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdsXf207N8gV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import os\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "#from torchmetrics import JaccardIndex\n",
        "#from thop import profile, clever_format\n",
        "import time\n",
        "\n",
        "#from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
        "#import torchprofile\n",
        "\n",
        "#from models.deeplabv2.deeplabv2 import get_deeplab_v2\n",
        "\n",
        "\n",
        "from torchmetrics import JaccardIndex\n",
        "from thop import profile, clever_format\n",
        "import time\n",
        "\n",
        "from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
        "import torchprofile\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNWddRGrt1kp"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q0xtwU5EhPW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4k4DE0eEjwr"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import pathlib\n",
        "drive.mount('/content/Drive')\n",
        "\n",
        "get_ipython().system('/content/Drive/MyDrive/Cityscapes/Cityscapes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqu-NDJHFkGk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuEJmYHCeerC"
      },
      "source": [
        "**GTA5 Dataset download**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjU52v_9P6Wj"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import pathlib\n",
        "drive.mount('/content/Drive')\n",
        "\n",
        "get_ipython().system('/content/Drive/MyDrive/GTA5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBX62-n6ZVgD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_09FKOE7XLEG"
      },
      "source": [
        "**Model Clone**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPllYnf-NPeU"
      },
      "outputs": [],
      "source": [
        "# Clone the GitHub repository\n",
        "!git clone https://github.com/Gabrysse/MLDL2024_project1.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kkLfxwKNZ5J"
      },
      "outputs": [],
      "source": [
        "# Navigate to the project directory\n",
        "%cd MLDL2024_project1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vi5RIWMWOJba"
      },
      "outputs": [],
      "source": [
        "#from models.deeplabv2.deeplabv2 import get_deeplab_v2\n",
        "from models.bisenet.build_bisenet import BiSeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAC9VIa40hM9"
      },
      "outputs": [],
      "source": [
        "# Set device to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnnzlL6eVNsV"
      },
      "source": [
        "**Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "032jMg_kVQWJ"
      },
      "outputs": [],
      "source": [
        "# Define training parameters\n",
        "epochs = 48\n",
        "learning_rate = 0.0001\n",
        "batch_size = 4\n",
        "train_resolution = (1280,720) #(1024, 512)\n",
        "test_resolution = (1024, 512)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3HtXvfzRp1R"
      },
      "outputs": [],
      "source": [
        "class CityscapesDataset(Dataset):\n",
        "  def __init__(self, root_dir, im_transform ):\n",
        "\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    root_dir (string): Directory with all the images.\n",
        "    transform (callable, optional): Optional transform to be applied on a sample.\n",
        "    \"\"\"\n",
        "    self.root_dir = root_dir\n",
        "    self.im_transform = im_transform\n",
        "    #self.lab_transform = lab_transform\n",
        "    self.images = []\n",
        "    for subdir, dirs, files in os.walk(root_dir):\n",
        "      for file in files:\n",
        "          self.images.append(os.path.join(subdir, file))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_name = self.images[idx]\n",
        "    image = Image.open(img_name).convert('RGB')\n",
        "    label_name = img_name.replace('images', 'gtFine').replace('_leftImg8bit','_gtFine_labelTrainIds')  #labelTrainIds\n",
        "\n",
        "\n",
        "    label = Image.open(label_name).convert('L')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Resize label using nearest-neighbor interpolation\n",
        "\n",
        "    label = TF.resize(label, (512, 1024), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "    label = np.array(label)  # Convert to numpy array\n",
        "    label = torch.from_numpy(label).long()  # Convert to LongTensor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if self.im_transform:\n",
        "\n",
        "      image = self.im_transform(image)\n",
        "\n",
        "\n",
        "\n",
        "    return image, label\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuDK4JddkZnR"
      },
      "outputs": [],
      "source": [
        "class GTA5Dataset(Dataset):\n",
        "  def __init__(self, root_dir, im_transform=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    root_dir (string): Directory with all the images and labels.\n",
        "    im_transform (callable, optional): Optional transform to be applied on a sample.\n",
        "    \"\"\"\n",
        "    self.root_dir = root_dir\n",
        "    self.im_transform = im_transform\n",
        "    self.transform=im_transform\n",
        "    self.images_dir = os.path.join(root_dir, 'images')\n",
        "    self.labels_dir = os.path.join(root_dir, 'labels')\n",
        "    self.images = [os.path.join(self.images_dir, file) for file in os.listdir(self.images_dir) if file.endswith('.png')]\n",
        "    self.id_to_trainid = {7: 0, 8: 1, 11: 2, 12: 3, 13: 4, 17: 5,\n",
        "                              19: 6, 20: 7, 21: 8, 22: 9, 23: 10, 24: 11, 25: 12,\n",
        "                              26: 13, 27: 14, 28: 15, 31: 16, 32: 17, 33: 18}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_name = self.images[idx]\n",
        "    image = Image.open(img_name).convert('RGB')\n",
        "    label_name = img_name.replace('images', 'labels')  # Assuming label images are in the 'labels' folder with the same name\n",
        "\n",
        "    label = Image.open(label_name)\n",
        "\n",
        "\n",
        "\n",
        "     # resize\n",
        "    image = image.resize((1280,720), Image.BICUBIC)\n",
        "    label = label.resize((1280,720), Image.NEAREST)\n",
        "\n",
        "    image = np.array(image)\n",
        "    label = np.array(label)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     # re-assign labels to match the format of Cityscapes\n",
        "    label_copy = 255 * np.ones(label.shape)\n",
        "    for k, v in self.id_to_trainid.items():\n",
        "        label_copy[label == k] = v\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    label_copy = torch.from_numpy(label_copy).long()  # Convert to LongTensor\n",
        "\n",
        "    if self.im_transform:\n",
        "      image = self.im_transform(image)\n",
        "\n",
        "\n",
        "\n",
        "    return image, label_copy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RxFO23631_3"
      },
      "source": [
        "**GTA5 Train Loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4lHdg9NmSag"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pathlib\n",
        "drive.mount('/content/Drive')\n",
        "\n",
        "get_ipython().system('/content/Drive/MyDrive/GTA5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NmNEEKrmeRf"
      },
      "outputs": [],
      "source": [
        "!ls /content/Drive/MyDrive/GTA5/GTA5/GTA5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0RCkMU_lAhz"
      },
      "outputs": [],
      "source": [
        "# Create the dataset\n",
        "\n",
        "im_transform=transforms.Compose([\n",
        "\n",
        "transforms.ToTensor(),\n",
        "#transforms.Resize(train_resolution),\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "gta5_dataset = GTA5Dataset(root_dir='/content/Drive/MyDrive/GTA5', im_transform=im_transform)\n",
        "\n",
        "print (len(gta5_dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xskaQe0nV0K"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(gta5_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UszT9qhVJl44"
      },
      "source": [
        "**Citescapes Train Loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjWP2n62UBn3"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0Yr3sirzs00"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Load the BiSeNet model\n",
        "model = BiSeNet(num_classes=19,context_path='resnet101') #'resnet18')  #'resnet101')  #BiSeNet\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "# Define the CrossEntropyLoss with ignore_index set to 255\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fNiWtGSzs8P"
      },
      "outputs": [],
      "source": [
        "# Define the metric for mIoU\n",
        "miou_metric = JaccardIndex(num_classes=19, task='multiclass' , ignore_index=255).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8p-LLxDzMNb"
      },
      "outputs": [],
      "source": [
        "# Function to compute latency\n",
        "def measure_latency(model, input_tensor, repetitions=100):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        start = time.time()\n",
        "        for _ in range(repetitions):\n",
        "            _ = model(input_tensor)\n",
        "        end = time.time()\n",
        "    latency = (end - start) / repetitions\n",
        "    return latency\n",
        "\n",
        "\n",
        "\n",
        "# Measure FLOPs and number of parameters\n",
        "\n",
        "\n",
        "dummy_input = torch.randn(1, 3, 1024, 512).to(device)\n",
        "\n",
        "height = 1024\n",
        "width = 512\n",
        "image =torch.zeros((1,3, height, width)).to(device)   # torch.randn(1,3, 1024, 512).to(device)#\n",
        "\n",
        "model.eval()\n",
        "flops = FlopCountAnalysis(model, image)\n",
        "print(flop_count_table(flops))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljOeeMI_Qlp6"
      },
      "outputs": [],
      "source": [
        "# Measure FLOPs and parameters using torchprofile\n",
        "dummy_input = torch.randn(1, 3, 1024,512).to(device)\n",
        "model.eval()\n",
        "flops = torchprofile.profile_macs(model, args=(dummy_input,))\n",
        "\n",
        "params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "print(f' flops={flops}\\n params={params} ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFgrmuBxbZL_"
      },
      "source": [
        "**IoU Calculation Function for Classes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpeSv9KSbXv6"
      },
      "outputs": [],
      "source": [
        "def fast_hist(a, b, n):\n",
        "    '''\n",
        "    a and b are label and prediction respectively\n",
        "    n is the number of classes\n",
        "    '''\n",
        "    #k = (a >= 0) & (a < n)\n",
        "    k = (b >= 0) & (b < n)\n",
        "    return np.bincount(n * a[k].astype(int) + b[k], minlength=n ** 2).reshape(n, n)\n",
        "\n",
        "\n",
        "def per_class_iou(hist):\n",
        "    epsilon = 1e-5\n",
        "    return (np.diag(hist)) / (hist.sum(1) + hist.sum(0) - np.diag(hist) + epsilon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Iwy_KA5TNwE"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RBnR6yWo_FO"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "drive.mount('/content/Drive')\n",
        "get_ipython().system('/content/Drive/MyDrive/Checkpoints/3a')\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8sBb7NnnvJI"
      },
      "outputs": [],
      "source": [
        "# Function to save the model\n",
        "def save_checkpoint(epoch, model, optimizer, save_dir='/content/Drive/MyDrive/Checkpoints/3a'):\n",
        "    # Ensure the save directory exists\n",
        "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Define the model filename with the epoch number\n",
        "    checkpoint_filename = f'checkpoint_epoch_{epoch}.pth'\n",
        "    checkpoint_path = os.path.join(save_dir, checkpoint_filename)\n",
        "\n",
        "    # Save the model and optimizer state dictionaries\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, checkpoint_path)\n",
        "    print(f'Model and optimizer saved to {checkpoint_path}')\n",
        "\n",
        "# Function to load the model\n",
        "def load_checkpoint(epoch, model, optimizer, save_dir='/content/Drive/MyDrive/Checkpoints/3a'):\n",
        "    checkpoint_filename = f'checkpoint_epoch_{epoch}.pth'\n",
        "    checkpoint_path = os.path.join(save_dir, checkpoint_filename)\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.isfile(checkpoint_path):\n",
        "        raise FileNotFoundError(f\"The specified file was not found: {checkpoint_path}\")\n",
        "\n",
        "    # Load the model and optimizer state dictionaries\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "\n",
        "    print(f'Model and optimizer loaded from {checkpoint_path}, resuming at epoch {start_epoch}')\n",
        "    return model, optimizer, start_epoch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1T9gxM10O1P"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "\n",
        "\n",
        "# Resume training from the last checkpoint if available\n",
        "resume_training =True   # Set this to True if you want to resume training\n",
        "\n",
        "epochs = 48 # Set this to the total number of epochs you want to train\n",
        "if resume_training:\n",
        "    epoch_to_resume =47   # Set this to the epoch from which you want to resume\n",
        "    try:\n",
        "        model, optimizer, start_epoch = load_checkpoint(epoch_to_resume, model, optimizer)\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(e)\n",
        "        start_epoch = 0\n",
        "else:\n",
        "    start_epoch = 0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(start_epoch, epochs):\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    miou_metric.reset()\n",
        "    counter=1\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "\n",
        "\n",
        "        loss = criterion(outputs[0], labels.long())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        miou_metric.update(outputs[0].argmax(dim=1), labels)\n",
        "\n",
        "\n",
        "\n",
        "    # Save the model every 4 epochs\n",
        "    if (epoch+1) % 4 == 0:\n",
        "        save_checkpoint(epoch, model, optimizer)\n",
        "\n",
        "\n",
        "\n",
        "    miou = miou_metric.compute().item()\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader)}, Train mIoU: {miou}')\n",
        "\n",
        "# Measure latency after training\n",
        "latency = measure_latency(model, dummy_input)\n",
        "print(f\"FLOPs: {flops}, Params: {params}, Latency: {latency:.6f} seconds\")\n",
        "\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTh46WFVkFLq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpQ67CRAKM-t"
      },
      "source": [
        "**Test Loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8F7HxrMSK3X"
      },
      "outputs": [],
      "source": [
        "# Define a transform if you need to preprocess the images\n",
        "transformed_dataset = CityscapesDataset(root_dir='/content/Drive/MyDrive/Cityscapes/Cityscapes/images/val',\n",
        "im_transform=transforms.Compose([\n",
        "\n",
        "transforms.ToTensor(),\n",
        "transforms.Resize((512,1024)),\n",
        "\n",
        "]), )\n",
        "\n",
        "\n",
        "test_loader = DataLoader(transformed_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ3uZ37_S_5C"
      },
      "source": [
        "**Inference and mIoU calculation on test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZd3_wXY4DbS"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "current_batch_size=labels.size(0)\n",
        "model.eval()\n",
        "miou_metric.reset()\n",
        "\n",
        "all_classes_iou=np.zeros(19)\n",
        "test_counter=0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #calcualting IoU for each class and for each (image,label) pair separately\n",
        "\n",
        "        for i in range (current_batch_size):\n",
        "\n",
        "          mask=labels[i,:,:].cpu().numpy().flatten() != 255\n",
        "          #hist=fast_hist(outputs[i,:,:,:].argmax(dim=0).cpu().numpy().flatten()[mask] , labels[i,:,:].cpu().numpy().flatten()[mask], 19)\n",
        "\n",
        "          hist=fast_hist(outputs[i,:,:,:].argmax(dim=0).cpu().numpy().flatten() , labels[i,:,:].cpu().numpy().flatten(), 19)\n",
        "\n",
        "          all_classes_iou=all_classes_iou+per_class_iou(hist)\n",
        "          test_counter = test_counter +1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwqEwifUcjgf"
      },
      "outputs": [],
      "source": [
        "test_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3roYr0uWqMQ"
      },
      "outputs": [],
      "source": [
        "all_classes_mIOU=(all_classes_iou/test_counter).round(3)  #calculating mean intersection over union for each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cZkG6AMWy5f"
      },
      "outputs": [],
      "source": [
        "all_classes_mIOU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhoYFSI4XY3p"
      },
      "outputs": [],
      "source": [
        "mIoU=all_classes_mIOU.mean()  #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKud9H4MXcjx"
      },
      "outputs": [],
      "source": [
        "mIoU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQDH0xjZdCoZ"
      },
      "source": [
        "**GTA5 Labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MktUOoKOdGMq"
      },
      "outputs": [],
      "source": [
        "from abc import ABCMeta\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "class BaseGTALabels(metaclass=ABCMeta):\n",
        "    pass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class GTA5Label:\n",
        "    ID: int\n",
        "    color: Tuple[int, int, int]\n",
        "\n",
        "\n",
        "class GTA5Labels_TaskCV2017(BaseGTALabels):\n",
        "    road = GTA5Label(ID=0, color=(128, 64, 128))\n",
        "    sidewalk = GTA5Label(ID=1, color=(244, 35, 232))\n",
        "    building = GTA5Label(ID=2, color=(70, 70, 70))\n",
        "    wall = GTA5Label(ID=3, color=(102, 102, 156))\n",
        "    fence = GTA5Label(ID=4, color=(190, 153, 153))\n",
        "    pole = GTA5Label(ID=5, color=(153, 153, 153))\n",
        "    light = GTA5Label(ID=6, color=(250, 170, 30))\n",
        "    sign = GTA5Label(ID=7, color=(220, 220, 0))\n",
        "    vegetation = GTA5Label(ID=8, color=(107, 142, 35))\n",
        "    terrain = GTA5Label(ID=9, color=(152, 251, 152))\n",
        "    sky = GTA5Label(ID=10, color=(70, 130, 180))\n",
        "    person = GTA5Label(ID=11, color=(220, 20, 60))\n",
        "    rider = GTA5Label(ID=12, color=(255, 0, 0))\n",
        "    car = GTA5Label(ID=13, color=(0, 0, 142))\n",
        "    truck = GTA5Label(ID=14, color=(0, 0, 70))\n",
        "    bus = GTA5Label(ID=15, color=(0, 60, 100))\n",
        "    train = GTA5Label(ID=16, color=(0, 80, 100))\n",
        "    motocycle = GTA5Label(ID=17, color=(0, 0, 230))\n",
        "    bicycle = GTA5Label(ID=18, color=(119, 11, 32))\n",
        "\n",
        "    list_ = [\n",
        "        road,\n",
        "        sidewalk,\n",
        "        building,\n",
        "        wall,\n",
        "        fence,\n",
        "        pole,\n",
        "        light,\n",
        "        sign,\n",
        "        vegetation,\n",
        "        terrain,\n",
        "        sky,\n",
        "        person,\n",
        "        rider,\n",
        "        car,\n",
        "        truck,\n",
        "        bus,\n",
        "        train,\n",
        "        motocycle,\n",
        "        bicycle,\n",
        "    ]\n",
        "\n",
        "    @property\n",
        "    def support_id_list(self):\n",
        "        ret = [label.ID for label in self.list_]\n",
        "        return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0BRk3RlZNiY"
      },
      "outputs": [],
      "source": [
        "class_labels = []\n",
        "for label_name, label in GTA5Labels_TaskCV2017.__dict__.items():\n",
        "  if isinstance(label, GTA5Label):\n",
        "    class_labels.append(label_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcvRxtpLZU1s"
      },
      "outputs": [],
      "source": [
        "class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLgml_o1al2p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR6dfnTWZNq6"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame\n",
        "all_classes_mIOU_DF = pd.DataFrame({\n",
        "'class_Label': class_labels,\n",
        "'class_IoU': all_classes_mIOU\n",
        "})\n",
        "\n",
        "all_classes_mIOU_DF\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}