{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJSeAJHbiQkZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9ufxTcqi1p_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJKFXHJni1tz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhbiuW2BU9Ec"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install torch torchvision torchmetrics thop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2od11trTFic",
        "outputId": "1eaa9d74-8ef4-4e72-a2de-3a59775faf6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchprofile\n",
            "  Downloading torchprofile-0.0.4-py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.10/dist-packages (from torchprofile) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from torchprofile) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.4 in /usr/local/lib/python3.10/dist-packages (from torchprofile) (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4->torchprofile) (12.5.82)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.4->torchprofile) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4->torchprofile) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->torchprofile) (1.3.0)\n",
            "Installing collected packages: torchprofile\n",
            "Successfully installed torchprofile-0.0.4\n"
          ]
        }
      ],
      "source": [
        "! pip install torchprofile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP_mEN9aTPSC",
        "outputId": "86f0e497-9489-49c0-b149-7ee2a9359615"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore) (1.25.2)\n",
            "Collecting yacs>=0.1.6 (from fvcore)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (6.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fvcore) (4.66.4)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (2.4.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fvcore) (9.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore) (0.9.0)\n",
            "Collecting iopath>=0.1.7 (from fvcore)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from iopath>=0.1.7->fvcore) (4.12.2)\n",
            "Collecting portalocker (from iopath>=0.1.7->fvcore)\n",
            "  Downloading portalocker-2.10.0-py3-none-any.whl (18 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=767f245ae4c246f6fea291d8f79803190127f1060d770c426dae1afb62f0005d\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=b4cf747cef707689ce779a66a93fca07790bb344461fc29ae56d6ff4171127e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.10.0 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install -U fvcore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdsXf207N8gV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import os\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "#from torchmetrics import JaccardIndex\n",
        "#from thop import profile, clever_format\n",
        "import time\n",
        "\n",
        "#from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
        "#import torchprofile\n",
        "\n",
        "#from models.deeplabv2.deeplabv2 import get_deeplab_v2\n",
        "\n",
        "\n",
        "from torchmetrics import JaccardIndex\n",
        "from thop import profile, clever_format\n",
        "import time\n",
        "\n",
        "from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
        "import torchprofile\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNWddRGrt1kp"
      },
      "source": [
        "**Cityscapes Dataset Download**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q0xtwU5EhPW"
      },
      "outputs": [],
      "source": [
        "#!pip install gdown\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4k4DE0eEjwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c208be7-4276-42e3-ec9e-c0986b3ed6c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/Drive\n",
            "/bin/bash: line 1: /content/Drive/MyDrive/Cityspaces/Cityspaces: Is a directory\n"
          ]
        }
      ],
      "source": [
        "#import gdown\n",
        "\n",
        "#url = 'https://drive.google.com/uc?id=1Qb4UrNsjvlU-wEsR9d7rckB0YS_LXgb2'\n",
        "#output = 'your_dataset.zip'  # Change this to the desired output filename\n",
        "#gdown.download(url, output, quiet=False)\n",
        "from google.colab import drive\n",
        "import pathlib\n",
        "drive.mount('/content/Drive')\n",
        "\n",
        "get_ipython().system('/content/Drive/MyDrive/Cityspaces/Cityspaces')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqu-NDJHFkGk"
      },
      "outputs": [],
      "source": [
        "#get_ipython().system('unzip /content/your_dataset.zip -d /content/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuEJmYHCeerC"
      },
      "source": [
        "**GTA5 Dataset download**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6C1U9y6hF4b"
      },
      "source": [
        "dataset link :  https://drive.google.com/file/d/1xYxlcMR2WFCpayNrW2-Rb7N-950vvl23/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjU52v_9P6Wj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65311082-ea78-445d-96be-19546150a71c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/Drive; to attempt to forcibly remount, call drive.mount(\"/content/Drive\", force_remount=True).\n",
            "/bin/bash: line 1: /content/Drive/MyDrive/GTA5: Is a directory\n"
          ]
        }
      ],
      "source": [
        "#url=' https://drive.google.com/uc?id=1xYxlcMR2WFCpayNrW2-Rb7N-950vvl23'\n",
        "#output = 'GTA5.zip'  # Change this to the desired output filename\n",
        "#gdown.download(url, output, quiet=False)\n",
        "from google.colab import drive\n",
        "import pathlib\n",
        "drive.mount('/content/Drive')\n",
        "\n",
        "get_ipython().system('/content/Drive/MyDrive/GTA5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBX62-n6ZVgD"
      },
      "outputs": [],
      "source": [
        "#get_ipython().system('unzip /content/GTA5.zip -d /content/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wJwQ6hxi4wh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_09FKOE7XLEG"
      },
      "source": [
        "**Model Clone**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPllYnf-NPeU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794d51e8-7c18-450e-d93b-287318001304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MLDL2024_project1'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 34 (delta 8), reused 4 (delta 4), pack-reused 16\u001b[K\n",
            "Receiving objects: 100% (34/34), 12.06 KiB | 12.06 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the GitHub repository\n",
        "!git clone https://github.com/Gabrysse/MLDL2024_project1.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kkLfxwKNZ5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fbb5541-2e42-49c4-ca8b-9eccf7165e63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MLDL2024_project1\n"
          ]
        }
      ],
      "source": [
        "# Navigate to the project directory\n",
        "%cd MLDL2024_project1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vi5RIWMWOJba"
      },
      "outputs": [],
      "source": [
        "#from models.deeplabv2.deeplabv2 import get_deeplab_v2\n",
        "from models.bisenet.build_bisenet import BiSeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAC9VIa40hM9"
      },
      "outputs": [],
      "source": [
        "# Set device to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnnzlL6eVNsV"
      },
      "source": [
        "**Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "032jMg_kVQWJ"
      },
      "outputs": [],
      "source": [
        "# Define training parameters\n",
        "epochs = 50\n",
        "learning_rate = 0.01\n",
        "batch_size = 4\n",
        "train_resolution = (1280,720) #(1024, 512)\n",
        "test_resolution = (1024, 512)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3HtXvfzRp1R"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CityscapesDataset(Dataset):\n",
        "  def __init__(self, root_dir, im_transform ):\n",
        "\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    root_dir (string): Directory with all the images.\n",
        "    transform (callable, optional): Optional transform to be applied on a sample.\n",
        "    \"\"\"\n",
        "    self.root_dir = root_dir\n",
        "    self.im_transform = im_transform\n",
        "    #self.lab_transform = lab_transform\n",
        "    self.images = []\n",
        "    for subdir, dirs, files in os.walk(root_dir):\n",
        "      for file in files:\n",
        "        if file.endswith('_gtFine_color.png'):\n",
        "          self.images.append(os.path.join(subdir, file))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_name = self.images[idx]\n",
        "    image = Image.open(img_name).convert('RGB')\n",
        "    label_name = img_name.replace('_gtFine_color.png', '_gtFine_labelTrainIds.png')  #labelTrainIds\n",
        "    label = Image.open(label_name)\n",
        "\n",
        "\n",
        "    # Resize label using nearest-neighbor interpolation\n",
        "    label = TF.resize(label, (1024, 512), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "    label = np.array(label)  # Convert to numpy array\n",
        "    label = torch.from_numpy(label).long()  # Convert to LongTensor\n",
        "\n",
        "\n",
        "    if self.im_transform:\n",
        "\n",
        "      image = self.im_transform(image)\n",
        "\n",
        "    # if self.lab_transform:\n",
        "    #   label = self.lab_transform(label)\n",
        "\n",
        "    return image, label\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuDK4JddkZnR"
      },
      "outputs": [],
      "source": [
        "class GTA5Dataset(Dataset):\n",
        "  def __init__(self, root_dir, im_transform=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    root_dir (string): Directory with all the images and labels.\n",
        "    im_transform (callable, optional): Optional transform to be applied on a sample.\n",
        "    \"\"\"\n",
        "    self.root_dir = root_dir\n",
        "    self.im_transform = im_transform\n",
        "    self.images_dir = os.path.join(root_dir, 'images')\n",
        "    self.labels_dir = os.path.join(root_dir, 'labels')\n",
        "    self.images = [os.path.join(self.images_dir, file) for file in os.listdir(self.images_dir) if file.endswith('.png')]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_name = self.images[idx]\n",
        "    image = Image.open(img_name).convert('RGB')\n",
        "    label_name = img_name.replace('images', 'labels')  # Assuming label images are in the 'labels' folder with the same name\n",
        "    label = Image.open(label_name)\n",
        "\n",
        "    # Resize label using nearest-neighbor interpolation\n",
        "    label = TF.resize(label, (1280,720) , interpolation=transforms.InterpolationMode.NEAREST)\n",
        "    label = np.array(label)  # Convert to numpy array\n",
        "\n",
        "    # Define the maximum valid label ID\n",
        "    max_valid_id = 18\n",
        "    # Set all label IDs greater than max_valid_id to the 'ignore' class (e.g., 255)\n",
        "    label[label > max_valid_id] = 255\n",
        "\n",
        "\n",
        "    label = torch.from_numpy(label).long()  # Convert to LongTensor\n",
        "\n",
        "    if self.im_transform:\n",
        "      image = self.im_transform(image)\n",
        "\n",
        "    return image, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RxFO23631_3"
      },
      "source": [
        "**GTA5 Train Loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4lHdg9NmSag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5afe15a4-dca2-4655-8edf-af01c486994c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/Drive; to attempt to forcibly remount, call drive.mount(\"/content/Drive\", force_remount=True).\n",
            "/bin/bash: line 1: /content/Drive/MyDrive/GTA5: Is a directory\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pathlib\n",
        "drive.mount('/content/Drive')\n",
        "\n",
        "get_ipython().system('/content/Drive/MyDrive/GTA5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NmNEEKrmeRf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f110de-d06e-482a-c8bf-2bd4f30c28c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/Drive/MyDrive/GTA5/GTA5/GTA5': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!ls /content/Drive/MyDrive/GTA5/GTA5/GTA5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0RCkMU_lAhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3a5b77-eb0e-41b4-8d48-de2ee9f7e695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500\n"
          ]
        }
      ],
      "source": [
        "# Create the dataset\n",
        "\n",
        "im_transform=transforms.Compose([\n",
        "\n",
        "transforms.ToTensor(),\n",
        "transforms.Resize(train_resolution),\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "gta5_dataset = GTA5Dataset(root_dir='/content/Drive/MyDrive/GTA5', im_transform=im_transform)\n",
        "\n",
        "print (len(gta5_dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xskaQe0nV0K"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(gta5_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UszT9qhVJl44"
      },
      "source": [
        "**Citescapes Train Loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjWP2n62UBn3"
      },
      "outputs": [],
      "source": [
        "# # Define a transform if you need to preprocess the images\n",
        "# transformed_dataset = CityscapesDataset(root_dir='/content/Cityscapes/Cityspaces/gtFine/train', #/content/Cityscapes/Cityspaces/gtFine/train\n",
        "# im_transform=transforms.Compose([\n",
        "\n",
        "# transforms.ToTensor(),\n",
        "# transforms.Resize(train_resolution),\n",
        "\n",
        "# ]), )\n",
        "\n",
        "\n",
        "# train_loader = DataLoader(transformed_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0Yr3sirzs00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac51444-b7d6-4950-cc1f-8ce041e88f45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 213MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:01<00:00, 152MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Load the DeepLabV2 model\n",
        "#model = get_deeplab_v2(num_classes=19, pretrain=False)\n",
        "\n",
        "# Load the BiSeNet model\n",
        "model = BiSeNet(num_classes=19,context_path='resnet18') #'resnet18')  #'resnet101')  #BiSeNet\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "# Define the CrossEntropyLoss with ignore_index set to 255\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fNiWtGSzs8P"
      },
      "outputs": [],
      "source": [
        "# Define the metric for mIoU\n",
        "miou_metric = JaccardIndex(num_classes=19, task='multiclass' , ignore_index=255).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8p-LLxDzMNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5887f7f-9021-4c03-db71-3273b388bb18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| module                                      | #parameters or shape   | #flops     |\n",
            "|:--------------------------------------------|:-----------------------|:-----------|\n",
            "| model                                       | 12.582M                | 25.78G     |\n",
            "|  saptial_path                               |  0.371M                |  5.088G    |\n",
            "|   saptial_path.convblock1                   |   1.856K               |   0.243G   |\n",
            "|    saptial_path.convblock1.conv1            |    1.728K              |    0.226G  |\n",
            "|    saptial_path.convblock1.bn               |    0.128K              |    16.777M |\n",
            "|   saptial_path.convblock2                   |   73.984K              |   2.424G   |\n",
            "|    saptial_path.convblock2.conv1            |    73.728K             |    2.416G  |\n",
            "|    saptial_path.convblock2.bn               |    0.256K              |    8.389M  |\n",
            "|   saptial_path.convblock3                   |   0.295M               |   2.42G    |\n",
            "|    saptial_path.convblock3.conv1            |    0.295M              |    2.416G  |\n",
            "|    saptial_path.convblock3.bn               |    0.512K              |    4.194M  |\n",
            "|  context_path.features                      |  11.69M                |  19.002G   |\n",
            "|   context_path.features.conv1               |   9.408K               |   1.233G   |\n",
            "|    context_path.features.conv1.weight       |    (64, 3, 7, 7)       |            |\n",
            "|   context_path.features.bn1                 |   0.128K               |   16.777M  |\n",
            "|    context_path.features.bn1.weight         |    (64,)               |            |\n",
            "|    context_path.features.bn1.bias           |    (64,)               |            |\n",
            "|   context_path.features.layer1              |   0.148M               |   4.849G   |\n",
            "|    context_path.features.layer1.0           |    73.984K             |    2.424G  |\n",
            "|    context_path.features.layer1.1           |    73.984K             |    2.424G  |\n",
            "|   context_path.features.layer2              |   0.526M               |   4.305G   |\n",
            "|    context_path.features.layer2.0           |    0.23M               |    1.885G  |\n",
            "|    context_path.features.layer2.1           |    0.295M              |    2.42G   |\n",
            "|   context_path.features.layer3              |   2.1M                 |   4.3G     |\n",
            "|    context_path.features.layer3.0           |    0.919M              |    1.882G  |\n",
            "|    context_path.features.layer3.1           |    1.181M              |    2.418G  |\n",
            "|   context_path.features.layer4              |   8.394M               |   4.298G   |\n",
            "|    context_path.features.layer4.0           |    3.673M              |    1.881G  |\n",
            "|    context_path.features.layer4.1           |    4.721M              |    2.417G  |\n",
            "|   context_path.features.fc                  |   0.513M               |            |\n",
            "|    context_path.features.fc.weight          |    (1000, 512)         |            |\n",
            "|    context_path.features.fc.bias            |    (1000,)             |            |\n",
            "|  attention_refinement_module1               |  66.304K               |  0.59M     |\n",
            "|   attention_refinement_module1.conv         |   65.792K              |   65.536K  |\n",
            "|    attention_refinement_module1.conv.weight |    (256, 256, 1, 1)    |            |\n",
            "|    attention_refinement_module1.conv.bias   |    (256,)              |            |\n",
            "|   attention_refinement_module1.bn           |   0.512K               |   0.512K   |\n",
            "|    attention_refinement_module1.bn.weight   |    (256,)              |            |\n",
            "|    attention_refinement_module1.bn.bias     |    (256,)              |            |\n",
            "|   attention_refinement_module1.avgpool      |                        |   0.524M   |\n",
            "|  attention_refinement_module2               |  0.264M                |  0.525M    |\n",
            "|   attention_refinement_module2.conv         |   0.263M               |   0.262M   |\n",
            "|    attention_refinement_module2.conv.weight |    (512, 512, 1, 1)    |            |\n",
            "|    attention_refinement_module2.conv.bias   |    (512,)              |            |\n",
            "|   attention_refinement_module2.bn           |   1.024K               |   1.024K   |\n",
            "|    attention_refinement_module2.bn.weight   |    (512,)              |            |\n",
            "|    attention_refinement_module2.bn.bias     |    (512,)              |            |\n",
            "|   attention_refinement_module2.avgpool      |                        |   0.262M   |\n",
            "|  supervision1                               |  4.883K                |            |\n",
            "|   supervision1.weight                       |   (19, 256, 1, 1)      |            |\n",
            "|   supervision1.bias                         |   (19,)                |            |\n",
            "|  supervision2                               |  9.747K                |            |\n",
            "|   supervision2.weight                       |   (19, 512, 1, 1)      |            |\n",
            "|   supervision2.bias                         |   (19,)                |            |\n",
            "|  feature_fusion_module                      |  0.176M                |  1.435G    |\n",
            "|   feature_fusion_module.convblock           |   0.175M               |   1.435G   |\n",
            "|    feature_fusion_module.convblock.conv1    |    0.175M              |    1.434G  |\n",
            "|    feature_fusion_module.convblock.bn       |    38                  |    0.311M  |\n",
            "|   feature_fusion_module.conv1               |   0.38K                |   0.361K   |\n",
            "|    feature_fusion_module.conv1.weight       |    (19, 19, 1, 1)      |            |\n",
            "|    feature_fusion_module.conv1.bias         |    (19,)               |            |\n",
            "|   feature_fusion_module.conv2               |   0.38K                |   0.361K   |\n",
            "|    feature_fusion_module.conv2.weight       |    (19, 19, 1, 1)      |            |\n",
            "|    feature_fusion_module.conv2.bias         |    (19,)               |            |\n",
            "|   feature_fusion_module.avgpool             |                        |   0.156M   |\n",
            "|  conv                                       |  0.38K                 |  0.189G    |\n",
            "|   conv.weight                               |   (19, 19, 1, 1)       |            |\n",
            "|   conv.bias                                 |   (19,)                |            |\n"
          ]
        }
      ],
      "source": [
        "# Function to compute latency\n",
        "def measure_latency(model, input_tensor, repetitions=100):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        start = time.time()\n",
        "        for _ in range(repetitions):\n",
        "            _ = model(input_tensor)\n",
        "        end = time.time()\n",
        "    latency = (end - start) / repetitions\n",
        "    return latency\n",
        "\n",
        "\n",
        "\n",
        "# Measure FLOPs and number of parameters\n",
        "\n",
        "\n",
        "dummy_input = torch.randn(1, 3, 1024, 512).to(device)\n",
        "\n",
        "height = 1024\n",
        "width = 512\n",
        "image =torch.zeros((1,3, height, width)).to(device)   # torch.randn(1,3, 1024, 512).to(device)#\n",
        "\n",
        "model.eval()\n",
        "flops = FlopCountAnalysis(model, image)\n",
        "print(flop_count_table(flops))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljOeeMI_Qlp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "381894a6-ae94-4893-f3de-da7b5d1f5fd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " flops=25739266789\n",
            " params=12581672 \n"
          ]
        }
      ],
      "source": [
        "# Measure FLOPs and parameters using torchprofile\n",
        "dummy_input = torch.randn(1, 3, 1024,512).to(device)\n",
        "model.eval()\n",
        "flops = torchprofile.profile_macs(model, args=(dummy_input,))\n",
        "\n",
        "params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "print(f' flops={flops}\\n params={params} ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFgrmuBxbZL_"
      },
      "source": [
        "**IoU Calculation Function for Classes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpeSv9KSbXv6"
      },
      "outputs": [],
      "source": [
        "def fast_hist(a, b, n):\n",
        "    '''\n",
        "    a and b are label and prediction respectively\n",
        "    n is the number of classes\n",
        "    '''\n",
        "    #k = (a >= 0) & (a < n)\n",
        "    k = (b >= 0) & (b < n)\n",
        "    return np.bincount(n * a[k].astype(int) + b[k], minlength=n ** 2).reshape(n, n)\n",
        "\n",
        "\n",
        "def per_class_iou(hist):\n",
        "    epsilon = 1e-5\n",
        "    return (np.diag(hist)) / (hist.sum(1) + hist.sum(0) - np.diag(hist) + epsilon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Iwy_KA5TNwE"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RBnR6yWo_FO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4429ead0-2afd-4504-abf5-1bf81a7db482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/Drive; to attempt to forcibly remount, call drive.mount(\"/content/Drive\", force_remount=True).\n",
            "/bin/bash: line 1: /content/Drive/MyDrive/Checkpoints/3a: Is a directory\n",
            "datasets  models  README.md  train.py  utils.py\n"
          ]
        }
      ],
      "source": [
        "#from pathlib import Path\n",
        "#import os\n",
        "#from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "drive.mount('/content/Drive')\n",
        "get_ipython().system('/content/Drive/MyDrive/Checkpoints/3a')\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8sBb7NnnvJI"
      },
      "outputs": [],
      "source": [
        "# Function to save the model\n",
        "def save_checkpoint(epoch, model, optimizer, save_dir='/content/Drive/MyDrive/Checkpoints/3a'):\n",
        "    # Ensure the save directory exists\n",
        "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Define the model filename with the epoch number\n",
        "    checkpoint_filename = f'checkpoint_epoch_{epoch}.pth'\n",
        "    checkpoint_path = os.path.join(save_dir, checkpoint_filename)\n",
        "\n",
        "    # Save the model and optimizer state dictionaries\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, checkpoint_path)\n",
        "    print(f'Model and optimizer saved to {checkpoint_path}')\n",
        "\n",
        "# Function to load the model\n",
        "def load_checkpoint(epoch, model, optimizer, save_dir='/content/Drive/MyDrive/Checkpoints/3a'):\n",
        "    checkpoint_filename = f'checkpoint_epoch_{epoch}.pth'\n",
        "    checkpoint_path = os.path.join(save_dir, checkpoint_filename)\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.isfile(checkpoint_path):\n",
        "        raise FileNotFoundError(f\"The specified file was not found: {checkpoint_path}\")\n",
        "\n",
        "    # Load the model and optimizer state dictionaries\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "\n",
        "    print(f'Model and optimizer loaded from {checkpoint_path}, resuming at epoch {start_epoch}')\n",
        "    return model, optimizer, start_epoch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1T9gxM10O1P",
        "outputId": "6cb1566c-ad82-43ff-a797-a4d70d7d2f41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and optimizer loaded from /content/Drive/MyDrive/Checkpoints/3a/checkpoint_epoch_20.pth, resuming at epoch 21\n",
            "Epoch [22/25], Loss: 0.09714148724079132, Train mIoU: 0.7728018164634705\n",
            "Epoch [23/25], Loss: 0.08791104231476783, Train mIoU: 0.7934992909431458\n",
            "Model and optimizer saved to /content/Drive/MyDrive/Checkpoints/3a/checkpoint_epoch_23.pth\n",
            "Epoch [24/25], Loss: 0.08672812994718551, Train mIoU: 0.795935869216919\n",
            "Epoch [25/25], Loss: 0.0841970064997673, Train mIoU: 0.7971428632736206\n",
            "FLOPs: 25739266789, Params: 12581672, Latency: 0.015234 seconds\n",
            "Training completed!\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "\n",
        "\n",
        "# Resume training from the last checkpoint if available\n",
        "resume_training =True   # Set this to True if you want to resume training\n",
        "\n",
        "epochs = 50 # Set this to the total number of epochs you want to train\n",
        "if resume_training:\n",
        "    epoch_to_resume =20 #9,19,29,39,49  # Set this to the epoch from which you want to resume\n",
        "    try:\n",
        "        model, optimizer, start_epoch = load_checkpoint(epoch_to_resume, model, optimizer)\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(e)\n",
        "        start_epoch = 0\n",
        "else:\n",
        "    start_epoch = 0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(start_epoch, epochs):\n",
        "#for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    miou_metric.reset()\n",
        "    counter=1\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        #labels = labels.squeeze(1)\n",
        "\n",
        "        loss = criterion(outputs[0], labels.long())\n",
        "        #print(loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #print(counter)\n",
        "        counter+=1\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        miou_metric.update(outputs[0].argmax(dim=1), labels)\n",
        "\n",
        "\n",
        "\n",
        "    # Save the model every 10 epochs\n",
        "    if (epoch+1) % 3 == 0:\n",
        "        save_checkpoint(epoch, model, optimizer)\n",
        "\n",
        "\n",
        "\n",
        "    miou = miou_metric.compute().item()\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader)}, Train mIoU: {miou}')\n",
        "\n",
        "# Measure latency after training\n",
        "latency = measure_latency(model, dummy_input)\n",
        "print(f\"FLOPs: {flops}, Params: {params}, Latency: {latency:.6f} seconds\")\n",
        "\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTh46WFVkFLq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpQ67CRAKM-t"
      },
      "source": [
        "**Test Loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8F7HxrMSK3X"
      },
      "outputs": [],
      "source": [
        "# Define a transform if you need to preprocess the images\n",
        "transformed_dataset = CityscapesDataset(root_dir='/content/Drive/MyDrive/Cityspaces/Cityspaces/gtFine/val', #/content/Cityscapes/Cityspaces/gtFine/train\n",
        "im_transform=transforms.Compose([\n",
        "\n",
        "transforms.ToTensor(),\n",
        "transforms.Resize(test_resolution),\n",
        "\n",
        "]), )\n",
        "\n",
        "\n",
        "test_loader = DataLoader(transformed_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ3uZ37_S_5C"
      },
      "source": [
        "**Inference and mIoU calculation on test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZd3_wXY4DbS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e6fed26-1947-42b0-cabe-7f2858024f8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n",
            "torch.Size([4, 19, 1024, 512]) torch.Size([4, 1024, 512])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "current_batch_size=labels.size(0)\n",
        "model.eval()\n",
        "miou_metric.reset()\n",
        "\n",
        "all_classes_iou=np.zeros(19)\n",
        "test_counter=0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Resize predictions to the original Cityscapes resolution\n",
        "        outputs = TF.resize(outputs, test_resolution, interpolation=Image.NEAREST)\n",
        "        print(outputs.shape , labels.shape)\n",
        "\n",
        "\n",
        "\n",
        "        #calcualting IoU for each class and for each (image,label) pair separately\n",
        "\n",
        "        for i in range (current_batch_size):\n",
        "\n",
        "          mask=labels[i,:,:].cpu().numpy().flatten() != 255\n",
        "          #hist=fast_hist(outputs[i,:,:,:].argmax(dim=0).cpu().numpy().flatten()[mask] , labels[i,:,:].cpu().numpy().flatten()[mask], 19)\n",
        "\n",
        "          hist=fast_hist(outputs[i,:,:,:].argmax(dim=0).cpu().numpy().flatten() , labels[i,:,:].cpu().numpy().flatten(), 19)\n",
        "\n",
        "          all_classes_iou=all_classes_iou+per_class_iou(hist)\n",
        "          test_counter = test_counter +1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwqEwifUcjgf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4a607b2-e981-4070-bfba-07f5ad8e7a72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "test_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3roYr0uWqMQ"
      },
      "outputs": [],
      "source": [
        "all_classes_mIOU=(all_classes_iou/test_counter).round(3)  #calculating mean intersection over union for each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cZkG6AMWy5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e96971-2d0b-4d73-9db1-a89afaabc5fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.065, 0.08 , 0.   , 0.   , 0.001, 0.003, 0.   , 0.   , 0.005,\n",
              "       0.   , 0.   , 0.016, 0.   , 0.   , 0.   , 0.001, 0.   , 0.001,\n",
              "       0.   ])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "all_classes_mIOU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhoYFSI4XY3p"
      },
      "outputs": [],
      "source": [
        "mIoU=all_classes_mIOU.mean()  #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKud9H4MXcjx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ead2b2d-dad2-4c6f-d664-d5bb1f0d628d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.009052631578947371"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "mIoU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQDH0xjZdCoZ"
      },
      "source": [
        "**GTA5 Labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MktUOoKOdGMq"
      },
      "outputs": [],
      "source": [
        "from abc import ABCMeta\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "class BaseGTALabels(metaclass=ABCMeta):\n",
        "    pass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class GTA5Label:\n",
        "    ID: int\n",
        "    color: Tuple[int, int, int]\n",
        "\n",
        "\n",
        "class GTA5Labels_TaskCV2017(BaseGTALabels):\n",
        "    road = GTA5Label(ID=0, color=(128, 64, 128))\n",
        "    sidewalk = GTA5Label(ID=1, color=(244, 35, 232))\n",
        "    building = GTA5Label(ID=2, color=(70, 70, 70))\n",
        "    wall = GTA5Label(ID=3, color=(102, 102, 156))\n",
        "    fence = GTA5Label(ID=4, color=(190, 153, 153))\n",
        "    pole = GTA5Label(ID=5, color=(153, 153, 153))\n",
        "    light = GTA5Label(ID=6, color=(250, 170, 30))\n",
        "    sign = GTA5Label(ID=7, color=(220, 220, 0))\n",
        "    vegetation = GTA5Label(ID=8, color=(107, 142, 35))\n",
        "    terrain = GTA5Label(ID=9, color=(152, 251, 152))\n",
        "    sky = GTA5Label(ID=10, color=(70, 130, 180))\n",
        "    person = GTA5Label(ID=11, color=(220, 20, 60))\n",
        "    rider = GTA5Label(ID=12, color=(255, 0, 0))\n",
        "    car = GTA5Label(ID=13, color=(0, 0, 142))\n",
        "    truck = GTA5Label(ID=14, color=(0, 0, 70))\n",
        "    bus = GTA5Label(ID=15, color=(0, 60, 100))\n",
        "    train = GTA5Label(ID=16, color=(0, 80, 100))\n",
        "    motocycle = GTA5Label(ID=17, color=(0, 0, 230))\n",
        "    bicycle = GTA5Label(ID=18, color=(119, 11, 32))\n",
        "\n",
        "    list_ = [\n",
        "        road,\n",
        "        sidewalk,\n",
        "        building,\n",
        "        wall,\n",
        "        fence,\n",
        "        pole,\n",
        "        light,\n",
        "        sign,\n",
        "        vegetation,\n",
        "        terrain,\n",
        "        sky,\n",
        "        person,\n",
        "        rider,\n",
        "        car,\n",
        "        truck,\n",
        "        bus,\n",
        "        train,\n",
        "        motocycle,\n",
        "        bicycle,\n",
        "    ]\n",
        "\n",
        "    @property\n",
        "    def support_id_list(self):\n",
        "        ret = [label.ID for label in self.list_]\n",
        "        return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0BRk3RlZNiY"
      },
      "outputs": [],
      "source": [
        "class_labels = []\n",
        "for label_name, label in GTA5Labels_TaskCV2017.__dict__.items():\n",
        "  if isinstance(label, GTA5Label):\n",
        "    class_labels.append(label_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcvRxtpLZU1s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d19972-da6b-4382-8ff6-636c712a598d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['road',\n",
              " 'sidewalk',\n",
              " 'building',\n",
              " 'wall',\n",
              " 'fence',\n",
              " 'pole',\n",
              " 'light',\n",
              " 'sign',\n",
              " 'vegetation',\n",
              " 'terrain',\n",
              " 'sky',\n",
              " 'person',\n",
              " 'rider',\n",
              " 'car',\n",
              " 'truck',\n",
              " 'bus',\n",
              " 'train',\n",
              " 'motocycle',\n",
              " 'bicycle']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLgml_o1al2p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR6dfnTWZNq6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "024fd4a6-19e9-4203-9307-268c8f727189"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   class_Label  class_IoU\n",
              "0         road  32.431505\n",
              "1     sidewalk  40.116434\n",
              "2     building   0.000000\n",
              "3         wall   0.000000\n",
              "4        fence   0.389912\n",
              "5         pole   1.641362\n",
              "6        light   0.000000\n",
              "7         sign   0.008262\n",
              "8   vegetation   2.700807\n",
              "9      terrain   0.000000\n",
              "10         sky   0.000000\n",
              "11      person   7.960447\n",
              "12       rider   0.057382\n",
              "13         car   0.006018\n",
              "14       truck   0.000000\n",
              "15         bus   0.276673\n",
              "16       train   0.000249\n",
              "17   motocycle   0.458351\n",
              "18     bicycle   0.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d7371ce2-c5c8-4a96-9c5b-9c0538c03b16\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class_Label</th>\n",
              "      <th>class_IoU</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>road</td>\n",
              "      <td>32.431505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sidewalk</td>\n",
              "      <td>40.116434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>building</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wall</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fence</td>\n",
              "      <td>0.389912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>pole</td>\n",
              "      <td>1.641362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>light</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>sign</td>\n",
              "      <td>0.008262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>vegetation</td>\n",
              "      <td>2.700807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>terrain</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>sky</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>person</td>\n",
              "      <td>7.960447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>rider</td>\n",
              "      <td>0.057382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>car</td>\n",
              "      <td>0.006018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>truck</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>bus</td>\n",
              "      <td>0.276673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>train</td>\n",
              "      <td>0.000249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>motocycle</td>\n",
              "      <td>0.458351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>bicycle</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7371ce2-c5c8-4a96-9c5b-9c0538c03b16')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d7371ce2-c5c8-4a96-9c5b-9c0538c03b16 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d7371ce2-c5c8-4a96-9c5b-9c0538c03b16');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5b5f4869-3394-407b-80b0-12396df203db\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b5f4869-3394-407b-80b0-12396df203db')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5b5f4869-3394-407b-80b0-12396df203db button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_dab1012b-3d1e-4012-9cdd-b0a69374feed\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('all_classes_mIOU_DF')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_dab1012b-3d1e-4012-9cdd-b0a69374feed button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('all_classes_mIOU_DF');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "all_classes_mIOU_DF",
              "summary": "{\n  \"name\": \"all_classes_mIOU_DF\",\n  \"rows\": 19,\n  \"fields\": [\n    {\n      \"column\": \"class_Label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"road\",\n          \"pole\",\n          \"person\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_IoU\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.414507347268492,\n        \"min\": 0.0,\n        \"max\": 40.11643413481465,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.0002486780796491443,\n          0.006017651770717584,\n          32.43150467920761\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Create a DataFrame\n",
        "all_classes_mIOU_DF = pd.DataFrame({\n",
        "'class_Label': class_labels,\n",
        "'class_IoU': all_classes_iou\n",
        "})\n",
        "\n",
        "all_classes_mIOU_DF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3BFrswajh3L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agdDp61Fi41m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCwYG2xri45j"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}