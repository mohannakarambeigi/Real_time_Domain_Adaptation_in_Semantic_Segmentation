{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfHducy3duRw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7Px2pA7SDFj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rf_tIixzSo2z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import os\n",
        "\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TO60nDAdTbIy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNWddRGrt1kp"
      },
      "source": [
        " Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4k4DE0eEjwr"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/Drive')\n",
        "get_ipython().system('/content/Drive/MyDrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuEJmYHCeerC"
      },
      "source": [
        "**GTA5 Dataset **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_09FKOE7XLEG"
      },
      "source": [
        "**Model Clone**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPllYnf-NPeU"
      },
      "outputs": [],
      "source": [
        "# Clone the GitHub repository\n",
        "!git clone https://github.com/Gabrysse/MLDL2024_project1.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kkLfxwKNZ5J"
      },
      "outputs": [],
      "source": [
        "# Navigate to the project directory\n",
        "%cd MLDL2024_project1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vi5RIWMWOJba"
      },
      "outputs": [],
      "source": [
        "#from models.deeplabv2.deeplabv2 import get_deeplab_v2\n",
        "from models.bisenet.build_bisenet import BiSeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHxU7YydbOqr"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAC9VIa40hM9"
      },
      "outputs": [],
      "source": [
        "# Set device to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqy92p1ITbNK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnnzlL6eVNsV"
      },
      "source": [
        "**Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "032jMg_kVQWJ"
      },
      "outputs": [],
      "source": [
        "# Define training parameters\n",
        "epochs = 50\n",
        "learning_rate = 0.0001\n",
        "batch_size = 4\n",
        "train_resolution = (1280,720) #(1024, 512)\n",
        "test_resolution = (1024, 512)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3HtXvfzRp1R"
      },
      "outputs": [],
      "source": [
        "class CityscapesDataset(Dataset):\n",
        "  def __init__(self, root_dir, im_transform ):\n",
        "\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    root_dir (string): Directory with all the images.\n",
        "    transform (callable, optional): Optional transform to be applied on a sample.\n",
        "    \"\"\"\n",
        "    self.root_dir = root_dir\n",
        "    self.im_transform = im_transform\n",
        "    #self.lab_transform = lab_transform\n",
        "    self.images = []\n",
        "    for subdir, dirs, files in os.walk(root_dir):\n",
        "      for file in files:\n",
        "          self.images.append(os.path.join(subdir, file))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_name = self.images[idx]\n",
        "    image = Image.open(img_name).convert('RGB')\n",
        "    label_name = img_name.replace('images', 'gtFine').replace('_leftImg8bit','_gtFine_labelTrainIds')  #labelTrainIds\n",
        "\n",
        "\n",
        "    label = Image.open(label_name).convert('L')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Resize label using nearest-neighbor interpolation\n",
        "    label = TF.resize(label, (512,1024 ), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "    label = np.array(label)  # Convert to numpy array\n",
        "    label = torch.from_numpy(label).long()  # Convert to LongTensor\n",
        "\n",
        "\n",
        "    if self.im_transform:\n",
        "\n",
        "      image = self.im_transform(image)\n",
        "\n",
        "\n",
        "\n",
        "    return image, label\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuDK4JddkZnR"
      },
      "outputs": [],
      "source": [
        "class GTA5Dataset(Dataset):\n",
        "  def __init__(self, root_dir, im_transform=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    root_dir (string): Directory with all the images and labels.\n",
        "    im_transform (callable, optional): Optional transform to be applied on a sample.\n",
        "    \"\"\"\n",
        "    self.root_dir = root_dir\n",
        "    self.im_transform = im_transform\n",
        "    self.transform=im_transform\n",
        "    self.images_dir = os.path.join(root_dir, 'images')\n",
        "    self.labels_dir = os.path.join(root_dir, 'labels')\n",
        "    self.images = [os.path.join(self.images_dir, file) for file in os.listdir(self.images_dir) if file.endswith('.png')]\n",
        "    self.id_to_trainid = {7: 0, 8: 1, 11: 2, 12: 3, 13: 4, 17: 5,\n",
        "                              19: 6, 20: 7, 21: 8, 22: 9, 23: 10, 24: 11, 25: 12,\n",
        "                              26: 13, 27: 14, 28: 15, 31: 16, 32: 17, 33: 18}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_name = self.images[idx]\n",
        "    image = Image.open(img_name).convert('RGB')\n",
        "    label_name = img_name.replace('images', 'labels')  # Assuming label images are in the 'labels' folder with the same name\n",
        "\n",
        "    label = Image.open(label_name)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # resize\n",
        "\n",
        "    image = image.resize((1280,720), Image.BICUBIC)\n",
        "    label = label.resize((1280,720), Image.NEAREST)\n",
        "\n",
        "    image = np.array(image)\n",
        "    label = np.array(label)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     # re-assign labels to match the format of Cityscapes\n",
        "    label_copy = 255 * np.ones(label.shape)\n",
        "    for k, v in self.id_to_trainid.items():\n",
        "        label_copy[label == k] = v\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    label_copy = torch.from_numpy(label_copy).long()  # Convert to LongTensor\n",
        "\n",
        "    if self.im_transform:\n",
        "      image = self.im_transform(image)\n",
        "\n",
        "\n",
        "\n",
        "    return image, label_copy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RxFO23631_3"
      },
      "source": [
        "**GTA5 Augmented Train Loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0RCkMU_lAhz"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "###-----   Augmentation Transforms:\n",
        "\n",
        "# Create the dataset with augmentations\n",
        "im_transform = transforms.Compose([\n",
        "transforms.ToTensor(),\n",
        "#transforms.Resize(train_resolution),\n",
        "\n",
        "#transforms.RandomHorizontalFlip(p=0.5),  # Apply horizontal flip with 50% probability\n",
        "transforms.RandomApply([transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5))], p=0.5),  # Apply Gaussian Blur with 50% probability\n",
        "transforms.RandomApply([transforms.ColorJitter(brightness=0.5)], p=0.5),  # Apply brightness adjustment with 50% probability\n",
        "\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "gta5_dataset = GTA5Dataset(root_dir='/content/Drive/MyDrive/GTA5', im_transform=im_transform)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xskaQe0nV0K"
      },
      "outputs": [],
      "source": [
        "gta5_loader = DataLoader(gta5_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efLvFSi9TpSS"
      },
      "outputs": [],
      "source": [
        "len(gta5_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kdr5y9MYpY68"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INdOxe22pZwY"
      },
      "source": [
        "**Cityscapes Train Data Loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAR7mNBDpZwZ"
      },
      "outputs": [],
      "source": [
        "# Define a transform if you need to preprocess the images\n",
        "transformed_dataset = CityscapesDataset(root_dir='/content/Drive/MyDrive/Cityscapes/Cityscapes/images/train',\n",
        "im_transform=transforms.Compose([\n",
        "\n",
        "transforms.ToTensor(),\n",
        "transforms.Resize((720, 1280 )),\n",
        "\n",
        "]), )\n",
        "\n",
        "\n",
        "cityscape_train_loader = DataLoader(transformed_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZY5BRvMpY_q",
        "outputId": "7708b751-4e5c-49a4-9d82-d91005f9da9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1572"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "len(cityscape_train_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goV3X29QpZCa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpQ67CRAKM-t"
      },
      "source": [
        "**Cityscapes Validation Data Loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8F7HxrMSK3X"
      },
      "outputs": [],
      "source": [
        "# Define a transform if you need to preprocess the images\n",
        "transformed_dataset = CityscapesDataset(root_dir='/content/Drive/MyDrive/Cityscapes/Cityscapes/images/val',\n",
        "im_transform=transforms.Compose([\n",
        "\n",
        "transforms.ToTensor(),\n",
        "transforms.Resize((512,1024)),\n",
        "\n",
        "]), )\n",
        "\n",
        "\n",
        "cityscape_val_loader = DataLoader(transformed_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTLxiqUTWgY5"
      },
      "outputs": [],
      "source": [
        "len(cityscape_val_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLmipLJvWgdE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7OV5zaXT8d9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0Yr3sirzs00"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define the CrossEntropyLoss with ignore_index set to 255\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFgrmuBxbZL_"
      },
      "source": [
        "**IoU Calculation Function for Classes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpeSv9KSbXv6"
      },
      "outputs": [],
      "source": [
        "def fast_hist(a, b, n):\n",
        "    '''\n",
        "    a and b are label and prediction respectively\n",
        "    n is the number of classes\n",
        "    '''\n",
        "    #k = (a >= 0) & (a < n)\n",
        "    k = (b >= 0) & (b < n)\n",
        "    return np.bincount(n * a[k].astype(int) + b[k], minlength=n ** 2).reshape(n, n)\n",
        "\n",
        "\n",
        "def per_class_iou(hist):\n",
        "    epsilon = 1e-5\n",
        "    return (np.diag(hist)) / (hist.sum(1) + hist.sum(0) - np.diag(hist) + epsilon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHdqsqOKU994"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sFGNvRuU_BI"
      },
      "source": [
        "**Discriminator Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stauaKHyVNhl"
      },
      "outputs": [],
      "source": [
        "class FCDiscriminator(nn.Module):\n",
        "  def __init__(self, num_classes, ndf=64):\n",
        "    super(FCDiscriminator, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(num_classes, ndf, kernel_size=4, stride=2, padding=1)\n",
        "    self.conv2 = nn.Conv2d(ndf, ndf*2, kernel_size=4, stride=2, padding=1)\n",
        "    self.conv3 = nn.Conv2d(ndf*2, ndf*4, kernel_size=4, stride=2, padding=1)\n",
        "    self.conv4 = nn.Conv2d(ndf*4, ndf*8, kernel_size=4, stride=2, padding=1)\n",
        "    self.classifier = nn.Conv2d(ndf*8, 1, kernel_size=4, stride=2, padding=1)\n",
        "    self.leaky_relu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.leaky_relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.leaky_relu(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.leaky_relu(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.leaky_relu(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLpscmtdVNlO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GifSRO_W0ZZj"
      },
      "source": [
        "**BiSeNet Model Loading**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXSjBgXEVNpe"
      },
      "outputs": [],
      "source": [
        "# Load the BiSeNet model\n",
        "model = BiSeNet(num_classes=19,context_path='resnet18')   #BiSeNet\n",
        "\n",
        "\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqqqrbPYVNru"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEy08oNukSUY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNLU2rlKrD6I"
      },
      "source": [
        "**Adversarial Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzpD_4MgU-CL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "\n",
        "# Assuming 'model' is your segmentation model and 'FCDiscriminator' is defined as above\n",
        "# Initialize models\n",
        "model = model.to('cuda')\n",
        "discriminator = FCDiscriminator(num_classes=19).to('cuda')  # Number of classes for segmentation task\n",
        "\n",
        "# Optimizers\n",
        "optimizer_model = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer_discriminator = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
        "\n",
        "# Loss functions\n",
        "criterion_segmentation = nn.CrossEntropyLoss(ignore_index=255)  # Loss function for segmentation model\n",
        "criterion_discriminator = nn.BCEWithLogitsLoss()                # Loss function for discriminator model\n",
        "\n",
        "# Create an infinite iterator for the smaller dataset\n",
        "target_iter = itertools.cycle(cityscape_train_loader)   # target is smaller\n",
        "\n",
        "# Main training loop\n",
        "for epoch in range(epochs):\n",
        "    # Reset the target iterator every epoch, because it is a larger dataset\n",
        "    source_iter = iter(gta5_loader)\n",
        "\n",
        "    # If source image loader is the larger dataset\n",
        "    for _ in range(len(gta5_loader)):\n",
        "        # Get a batch from the source dataset\n",
        "        source_data = next(source_iter)\n",
        "        source_images, source_labels = source_data\n",
        "        source_images = source_images.to('cuda')\n",
        "        source_labels = source_labels.to('cuda')\n",
        "\n",
        "        # Get a batch from the target dataset\n",
        "        target_data = next(target_iter)\n",
        "        target_images, _ = target_data\n",
        "        target_images = target_images.to('cuda')\n",
        "\n",
        "        ############### Train segmentation model with source and target ##################\n",
        "\n",
        "        ########## Train segmentation model with source images ##########\n",
        "        model.train()\n",
        "        optimizer_model.zero_grad()\n",
        "        source_pred = model(source_images)\n",
        "        loss_segmentation = criterion_segmentation(source_pred[0], source_labels)\n",
        "        loss_segmentation.backward()\n",
        "\n",
        "        ########## Train segmentation model with target images ##########\n",
        "        target_pred = model(target_images)\n",
        "        target_pred_softmax = F.softmax(target_pred[0], dim=1)  # Apply softmax to the model output\n",
        "\n",
        "        # Don't accumulate grads in Discriminator\n",
        "        for param in discriminator.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        pred_target = discriminator(target_pred_softmax)  # Use softmax output as input for discriminator\n",
        "\n",
        "        # Very important: Label as 1 for target to fool discriminator\n",
        "        target_label = torch.ones_like(pred_target).to('cuda')\n",
        "\n",
        "        loss_adv = criterion_discriminator(pred_target, target_label)\n",
        "\n",
        "        loss_adv= 0.001*loss_adv  #weighting loss_adv with 0.001\n",
        "\n",
        "        # Backpropagate the adversarial loss through the segmentation model only\n",
        "        loss_adv.backward()  # Backpropagate loss to update only segmentation model's parameters\n",
        "\n",
        "        ############# Train discriminator with source and target ###########################\n",
        "\n",
        "        ########## Train discriminator with source ##########\n",
        "        source_pred = model(source_images)\n",
        "        source_pred = source_pred[0].detach()  # Detach source_pred from the graph to prevent gradients from flowing into 'model'\n",
        "\n",
        "        # Enable gradient computation for discriminator parameters\n",
        "        for param in discriminator.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        discriminator_out = discriminator(F.softmax(source_pred, dim=1))\n",
        "\n",
        "        # Calculate loss for discriminator\n",
        "        source_label = torch.ones_like(discriminator_out).to('cuda')  # Label as 1 for source\n",
        "        loss_adv = criterion_discriminator(discriminator_out, source_label)\n",
        "\n",
        "        optimizer_discriminator.zero_grad()\n",
        "        loss_adv.backward()\n",
        "\n",
        "        ########## Train discriminator with target ##########\n",
        "        target_pred = model(target_images)\n",
        "        target_pred = target_pred[0].detach()  # Detach target_pred from the graph to prevent gradients from flowing into 'model'\n",
        "\n",
        "        discriminator_out = discriminator(F.softmax(target_pred, dim=1))\n",
        "\n",
        "        # Calculate loss for discriminator\n",
        "        target_label = torch.zeros_like(discriminator_out).to('cuda')  # Label as 0 for target\n",
        "        loss_adv = criterion_discriminator(discriminator_out, target_label)\n",
        "        loss_adv.backward()\n",
        "\n",
        "        # Update the models\n",
        "        optimizer_model.step()\n",
        "        optimizer_discriminator.step()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmQSb2xtVCbS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ3uZ37_S_5C"
      },
      "source": [
        "**Inference and mIoU calculation on test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZd3_wXY4DbS"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "\n",
        "all_classes_iou=np.zeros(19)\n",
        "test_counter=0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in cityscape_val_loader:          #test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #calcualting IoU for each class and for each (image,label) pair separately\n",
        "\n",
        "        for i in range (batch_size):\n",
        "\n",
        "\n",
        "          hist=fast_hist(outputs[i,:,:,:].argmax(dim=0).cpu().numpy().flatten() , labels[i,:,:].cpu().numpy().flatten(), 19)\n",
        "\n",
        "          all_classes_iou=all_classes_iou+per_class_iou(hist)\n",
        "          test_counter = test_counter +1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwqEwifUcjgf"
      },
      "outputs": [],
      "source": [
        "test_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3roYr0uWqMQ"
      },
      "outputs": [],
      "source": [
        "all_classes_mIOU=(all_classes_iou/test_counter).round(3)  #calculating mean intersection over union for each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cZkG6AMWy5f"
      },
      "outputs": [],
      "source": [
        "all_classes_mIOU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhoYFSI4XY3p"
      },
      "outputs": [],
      "source": [
        "mIoU=all_classes_mIOU.mean()  #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKud9H4MXcjx"
      },
      "outputs": [],
      "source": [
        "mIoU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQDH0xjZdCoZ"
      },
      "source": [
        "**GTA5 Labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MktUOoKOdGMq"
      },
      "outputs": [],
      "source": [
        "from abc import ABCMeta\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "class BaseGTALabels(metaclass=ABCMeta):\n",
        "    pass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class GTA5Label:\n",
        "    ID: int\n",
        "    color: Tuple[int, int, int]\n",
        "\n",
        "\n",
        "class GTA5Labels_TaskCV2017(BaseGTALabels):\n",
        "    road = GTA5Label(ID=0, color=(128, 64, 128))\n",
        "    sidewalk = GTA5Label(ID=1, color=(244, 35, 232))\n",
        "    building = GTA5Label(ID=2, color=(70, 70, 70))\n",
        "    wall = GTA5Label(ID=3, color=(102, 102, 156))\n",
        "    fence = GTA5Label(ID=4, color=(190, 153, 153))\n",
        "    pole = GTA5Label(ID=5, color=(153, 153, 153))\n",
        "    light = GTA5Label(ID=6, color=(250, 170, 30))\n",
        "    sign = GTA5Label(ID=7, color=(220, 220, 0))\n",
        "    vegetation = GTA5Label(ID=8, color=(107, 142, 35))\n",
        "    terrain = GTA5Label(ID=9, color=(152, 251, 152))\n",
        "    sky = GTA5Label(ID=10, color=(70, 130, 180))\n",
        "    person = GTA5Label(ID=11, color=(220, 20, 60))\n",
        "    rider = GTA5Label(ID=12, color=(255, 0, 0))\n",
        "    car = GTA5Label(ID=13, color=(0, 0, 142))\n",
        "    truck = GTA5Label(ID=14, color=(0, 0, 70))\n",
        "    bus = GTA5Label(ID=15, color=(0, 60, 100))\n",
        "    train = GTA5Label(ID=16, color=(0, 80, 100))\n",
        "    motocycle = GTA5Label(ID=17, color=(0, 0, 230))\n",
        "    bicycle = GTA5Label(ID=18, color=(119, 11, 32))\n",
        "\n",
        "    list_ = [\n",
        "        road,\n",
        "        sidewalk,\n",
        "        building,\n",
        "        wall,\n",
        "        fence,\n",
        "        pole,\n",
        "        light,\n",
        "        sign,\n",
        "        vegetation,\n",
        "        terrain,\n",
        "        sky,\n",
        "        person,\n",
        "        rider,\n",
        "        car,\n",
        "        truck,\n",
        "        bus,\n",
        "        train,\n",
        "        motocycle,\n",
        "        bicycle,\n",
        "    ]\n",
        "\n",
        "    @property\n",
        "    def support_id_list(self):\n",
        "        ret = [label.ID for label in self.list_]\n",
        "        return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0BRk3RlZNiY"
      },
      "outputs": [],
      "source": [
        "class_labels = []\n",
        "for label_name, label in GTA5Labels_TaskCV2017.__dict__.items():\n",
        "  if isinstance(label, GTA5Label):\n",
        "    class_labels.append(label_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcvRxtpLZU1s"
      },
      "outputs": [],
      "source": [
        "class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLgml_o1al2p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR6dfnTWZNq6"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame\n",
        "all_classes_mIOU_DF = pd.DataFrame({\n",
        "'class_Label': class_labels,\n",
        "'class_IoU': all_classes_mIOU\n",
        "})\n",
        "\n",
        "all_classes_mIOU_DF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nu1PFhLBqxOV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}